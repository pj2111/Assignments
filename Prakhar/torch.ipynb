{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1])\n",
    "print(a)\n",
    "b = torch.tensor([4])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar = torch.zeros([3])\n",
    "ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a0 = torch.zeros([3,4])\n",
    "print(a0)\n",
    "a0.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5290, 0.3358, 0.6869, 0.9866],\n",
       "        [0.0244, 0.0178, 0.3183, 0.1810],\n",
       "        [0.5687, 0.9986, 0.1377, 0.7378]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "as1 = torch.ones(3,2)\n",
    "print(as1)\n",
    "arand = torch.rand(3,4)\n",
    "arand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.1477e-41,  0.0000e+00,  1.3452e-43],\n",
       "        [ 0.0000e+00, -8.1922e+03,  4.5862e-41]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aemp = torch.empty(2,3)\n",
    "aemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  9,  9,  8],\n",
       "        [ 6,  7,  6,  7],\n",
       "        [ 9,  7, 11,  8]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randa = torch.randint(high=12, low=6, size=[3,4])\n",
    "randa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False])\n",
      "tensor([True])\n",
      "tensor([0])\n",
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "n = torch.tensor([65.43])\n",
    "\n",
    "print(n<0)\n",
    "print(n>0)\n",
    "\n",
    "print((n < 0).long())\n",
    "print((n > 0).long())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(torch.tensor(False), torch.tensor(1), torch.tensor(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7,  9,  9,  8],\n",
      "        [ 6,  7,  6,  7],\n",
      "        [ 9,  7, 11,  8]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 63,  63,  63,  63],\n",
       "        [ 63,  63,  63,  63],\n",
       "        [ 63,  63, 567,  63]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(randa)\n",
    "torch.where(randa > 10, torch.tensor(567), torch.tensor(63))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "torch.Size([3, 1])\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "n_3r = torch.tensor([5.7, 62, 46])\n",
    "print(n_3r.shape)\n",
    "n_3c = torch.tensor([[5],[7],[1]])\n",
    "print(n_3c.shape)\n",
    "n_3rc = torch.tensor([[3, 4, 5]])\n",
    "print(n_3rc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]])\n",
      "tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "a0like = torch.zeros_like(randa)\n",
    "print(a0like)\n",
    "\n",
    "a1like = torch.ones_like(randa)\n",
    "print(a1like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"check_uniform_bounds\" not implemented for 'Long'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.5486, 0.4106, 0.1831])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making tensors of random numbers\n",
    "try:\n",
    "    arandlike = torch.rand_like(torch.tensor([1, 5, 7]))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "arandlike = torch.rand_like(torch.tensor([1.5, 5.2, 77.5]))\n",
    "arandlike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"check_uniform_bounds\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m arandlike \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrand_like(torch\u001b[39m.\u001b[39;49mtensor([\u001b[39m1\u001b[39;49m, \u001b[39m5\u001b[39;49m, \u001b[39m7\u001b[39;49m]))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"check_uniform_bounds\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "arandlike = torch.rand_like(torch.tensor([1, 5, 7]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.        ,  6.55555556,  8.11111111,  9.66666667, 11.22222222,\n",
       "       12.77777778, 14.33333333, 15.88888889, 17.44444444, 19.        ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "rangenum = np.linspace(5,19,10)\n",
    "rangenum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.0000,  6.5556,  8.1111,  9.6667, 11.2222, 12.7778, 14.3333, 15.8889,\n",
       "        17.4444, 19.0000])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rangets = torch.linspace(5,19,10)\n",
    "rangets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = torch.eye(5)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2446, 0.8012, 0.4593,  ..., 0.2071, 0.8065, 0.5329],\n",
      "         [0.2194, 0.5919, 0.1504,  ..., 0.3340, 0.1386, 0.7412],\n",
      "         [0.4578, 0.6065, 0.2774,  ..., 0.6390, 0.5760, 0.9973],\n",
      "         ...,\n",
      "         [0.0761, 0.9789, 0.8705,  ..., 0.8140, 0.8399, 0.5644],\n",
      "         [0.5740, 0.5844, 0.8958,  ..., 0.1667, 0.8461, 0.5011],\n",
      "         [0.7874, 0.8376, 0.5795,  ..., 0.4177, 0.8985, 0.6112]],\n",
      "\n",
      "        [[0.1282, 0.0703, 0.3182,  ..., 0.3222, 0.1267, 0.9810],\n",
      "         [0.7494, 0.8415, 0.6890,  ..., 0.3192, 0.2293, 0.9516],\n",
      "         [0.9372, 0.5954, 0.9073,  ..., 0.5777, 0.7945, 0.6816],\n",
      "         ...,\n",
      "         [0.2587, 0.5729, 0.7532,  ..., 0.3931, 0.6413, 0.7946],\n",
      "         [0.9009, 0.8711, 0.6035,  ..., 0.5305, 0.9193, 0.5402],\n",
      "         [0.0814, 0.8222, 0.0502,  ..., 0.8866, 0.2472, 0.3453]],\n",
      "\n",
      "        [[0.3183, 0.6032, 0.1082,  ..., 0.5978, 0.5545, 0.3205],\n",
      "         [0.5977, 0.5783, 0.3207,  ..., 0.4012, 0.3091, 0.3655],\n",
      "         [0.7068, 0.2024, 0.6518,  ..., 0.7068, 0.1921, 0.6640],\n",
      "         ...,\n",
      "         [0.1934, 0.5190, 0.8040,  ..., 0.2386, 0.3995, 0.2661],\n",
      "         [0.8206, 0.7159, 0.6170,  ..., 0.9639, 0.3099, 0.6550],\n",
      "         [0.8765, 0.0972, 0.1932,  ..., 0.8238, 0.6054, 0.9166]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.3938, 0.9782, 0.4697,  ..., 0.3110, 0.0584, 0.0678],\n",
      "         [0.8871, 0.7005, 0.6455,  ..., 0.6890, 0.1729, 0.0632],\n",
      "         [0.0835, 0.4803, 0.6263,  ..., 0.1095, 0.9009, 0.1643],\n",
      "         ...,\n",
      "         [0.9687, 0.5564, 0.2098,  ..., 0.3327, 0.0988, 0.3928],\n",
      "         [0.2561, 0.8259, 0.5543,  ..., 0.7909, 0.4738, 0.5174],\n",
      "         [0.2867, 0.3057, 0.9794,  ..., 0.3191, 0.3507, 0.6433]],\n",
      "\n",
      "        [[0.5447, 0.3975, 0.9696,  ..., 0.6000, 0.9449, 0.6794],\n",
      "         [0.5486, 0.2189, 0.7246,  ..., 0.0938, 0.6831, 0.1865],\n",
      "         [0.5500, 0.8786, 0.3728,  ..., 0.2264, 0.4364, 0.9733],\n",
      "         ...,\n",
      "         [0.8358, 0.3126, 0.2071,  ..., 0.4916, 0.9669, 0.2185],\n",
      "         [0.4974, 0.3817, 0.7298,  ..., 0.2247, 0.2494, 0.0371],\n",
      "         [0.1081, 0.4517, 0.8788,  ..., 0.2707, 0.1157, 0.2083]],\n",
      "\n",
      "        [[0.8704, 0.4312, 0.9735,  ..., 0.3534, 0.4729, 0.3817],\n",
      "         [0.2502, 0.6571, 0.9880,  ..., 0.8693, 0.1803, 0.6412],\n",
      "         [0.5270, 0.4509, 0.1179,  ..., 0.6960, 0.9857, 0.8619],\n",
      "         ...,\n",
      "         [0.4186, 0.6825, 0.4191,  ..., 0.4735, 0.8318, 0.6205],\n",
      "         [0.7389, 0.3240, 0.9350,  ..., 0.0832, 0.3028, 0.6416],\n",
      "         [0.8554, 0.2867, 0.9439,  ..., 0.2043, 0.3037, 0.9970]]])\n",
      "torch.Size([199, 57, 66])\n",
      "torch.Size([57, 66])\n",
      "torch.Size([66])\n"
     ]
    }
   ],
   "source": [
    "h1 = torch.rand(size= [199,57,66])\n",
    "print(h1)\n",
    "print(h1.shape)\n",
    "print(h1[0].shape)\n",
    "print(h1[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2992, 0.3614, 0.5616])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "ys = torch.rand(3)\n",
    "print(ys)\n",
    "print(ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2992, 0.3614, 0.5616]])\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "us = ys.unsqueeze(dim=0)\n",
    "print(us)\n",
    "print(us.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2992],\n",
      "        [0.3614],\n",
      "        [0.5616]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "us = ys.unsqueeze(dim=1)\n",
    "print(us)\n",
    "print(us.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7438, 0.6384, 0.5963]],\n",
      "\n",
      "        [[0.2702, 0.7338, 0.0466]],\n",
      "\n",
      "        [[0.2596, 0.7646, 0.5064]],\n",
      "\n",
      "        [[0.9306, 0.3998, 0.0830]]])\n",
      "tensor(0.5064)\n"
     ]
    }
   ],
   "source": [
    "ys123 = torch.rand(4,1,3)\n",
    "print(ys123)\n",
    "print(ys123[2][0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 3])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "sqys123 = torch.squeeze(ys123)\n",
    "print(ys123.shape)\n",
    "print(sqys123.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3668, 0.3776],\n",
      "        [0.2720, 0.1192],\n",
      "        [0.4105, 0.1680]])\n",
      "tensor([[[0.3668, 0.3776],\n",
      "         [0.2720, 0.1192],\n",
      "         [0.4105, 0.1680]]])\n",
      "torch.Size([1, 3, 2])\n",
      "tensor([[[0.3668, 0.3776]],\n",
      "\n",
      "        [[0.2720, 0.1192]],\n",
      "\n",
      "        [[0.4105, 0.1680]]])\n",
      "torch.Size([3, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "ys1 = torch.rand(3,2)\n",
    "print(ys1)\n",
    "print(ys1.unsqueeze(dim=0))\n",
    "print(ys1.unsqueeze(dim=0).shape)\n",
    "print(ys1.unsqueeze(dim=1))\n",
    "print(ys1.unsqueeze(dim=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6267, 0.8758],\n",
      "        [0.9457, 0.1839],\n",
      "        [0.3365, 0.8620]])\n",
      "tensor([[0.6267, 0.8758],\n",
      "        [0.9457, 0.1839],\n",
      "        [0.3365, 0.8620]])\n",
      "torch.Size([3, 2])\n",
      "tensor([[0.6267, 0.8758],\n",
      "        [0.9457, 0.1839],\n",
      "        [0.3365, 0.8620]])\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "ys1 = torch.rand(3,2)\n",
    "print(ys1)\n",
    "print(ys1.squeeze(dim=0))\n",
    "print(ys1.squeeze(dim=0).shape)\n",
    "print(ys1.squeeze(dim=1))\n",
    "print(ys1.squeeze(dim=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 2, 1, 2, 2, 1, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = torch.tensor([0.2, 8.5, 3.25])\n",
    "samples = torch.multinomial(j, 10, replacement = True)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.0000,  0.0000,  1.0000],\n",
      "        [ 8.0000, 10.0000,  9.0000],\n",
      "        [ 0.5000,  0.7000,  0.9000]])\n",
      "tensor([[0, 0, 0, 0, 2],\n",
      "        [2, 2, 0, 2, 0],\n",
      "        [1, 0, 1, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "m2 = torch.tensor([[5, 0, 1],\n",
    "                   [8, 10, 9],\n",
    "                   [0.5, 0.7, 0.9]])\n",
    "print(m2)\n",
    "p2 = torch.multinomial(m2, 5, True)\n",
    "print(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 5, 7]])\n",
      "tensor([[5, 6, 7, 8]])\n",
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "k = torch.tensor([[1,2,5,7]])\n",
    "l = torch.tensor([[5,6,7,8]])\n",
    "m = torch.tensor(5)\n",
    "print(k)\n",
    "print(l)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "print(k.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 5, 7],\n",
       "        [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcat = torch.cat((k,l), dim=0) # dim =1 ==>tensor([[1, 2, 5, 7, 5]])\n",
    "\n",
    "outcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero-dimensional tensor (at position 1) cannot be concatenated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 8,  8,  5,  5,  9, 97, 67, 96, 56, 55],\n",
       "        [ 9,  9,  9,  9,  6, 63, 92, 52, 38, 78]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    outcol = torch.cat((k, m), dim=1)\n",
    "    outcol\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "p = torch.randint(low=5, high=10, size=(2, 5))\n",
    "q = torch.randint(low=10, high=100, size=(2, 5))\n",
    "outcol = torch.cat((p, q), dim=1)\n",
    "outcol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = torch.arange(0,5)\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack() takes from 1 to 2 positional arguments but 4 were given\n",
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [1, 2, 3, 4, 5],\n",
      "        [2, 3, 4, 5, 6],\n",
      "        [4, 5, 6, 7, 8]])\n",
      "torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "s1 = torch.arange(0, 5)  # all tensors are 1r and 5c shape\n",
    "s2 = torch.arange(1, 6)\n",
    "s3 = torch.arange(2, 7)\n",
    "s4 = torch.arange(4, 9)\n",
    "try:\n",
    "    s5 = torch.stack(s1, s2, s3, s4)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "s5 = torch.stack([s1, s2, s3, s4])\n",
    "print(s5)\n",
    "print(s5.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m s6 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat((s1,s2,s3,s4),dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m s6\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "s6 = torch.cat((s1,s2,s3,s4),dim=1)\n",
    "s6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 4],\n",
      "        [1, 2, 3, 5],\n",
      "        [2, 3, 4, 6],\n",
      "        [3, 4, 5, 7],\n",
      "        [4, 5, 6, 8]])\n",
      "torch.Size([5, 4])\n"
     ]
    }
   ],
   "source": [
    "s5 = torch.stack([s1, s2, s3, s4], dim=1)\n",
    "print(s5)\n",
    "print(s5.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [1, 2, 3, 4, 5],\n",
      "        [2, 3, 4, 5, 6],\n",
      "        [4, 5, 6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "print(type(s5))\n",
    "# print(torch.transpose(s5)) #TypeError: transpose() received an invalid combination of arguments - got (Tensor), but expected one of:\n",
    "print(s5.transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tlo = torch.tril(torch.ones(5,5))\n",
    "tlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5., 5., 5.],\n",
       "        [0., 5., 5., 5., 5.],\n",
       "        [0., 0., 5., 5., 5.],\n",
       "        [0., 0., 0., 5., 5.],\n",
       "        [0., 0., 0., 0., 5.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tup = torch.triu(torch.ones(5, 5) * 5)\n",
    "tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskout = torch.zeros(5, 5).masked_fill(torch.tril(torch.ones(5, 5)) == 0,float('-inf'))\n",
    "maskout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "(tensor([[False, False, False, False, False],\n",
      "        [ True, False, False, False, False],\n",
      "        [ True,  True, False, False, False],\n",
      "        [ True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True, False]]), -inf)\n"
     ]
    }
   ],
   "source": [
    "a = torch.triu(torch.ones(5, 5))== 0,float('-inf')\n",
    "print(type(a))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(maskout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 6, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 5, 2])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose\n",
    "\n",
    "input = torch.rand(5, 6, 2)\n",
    "print(input.shape)\n",
    "inputout = input.transpose(0, 1)\n",
    "inputout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te1 = torch.tensor([1,2,3], dtype=torch.float32)\n",
    "te1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin1 = nn.Linear(3,1,bias=False)\n",
    "lin2 = nn.Linear(1,1, bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=3, out_features=1, bias=False)\n",
      "<generator object Module.parameters at 0x7fd8c879fc80>\n"
     ]
    }
   ],
   "source": [
    "print(lin1)\n",
    "print(lin1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3154], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1 = lin1(te1)\n",
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1038], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2 = lin2(out1)\n",
    "out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m_/_x8t4kvn0334z53zdz_86l400000gp/T/ipykernel_33977/2936821666.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  s = F.softmax(te1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0900, 0.2447, 0.6652])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = F.softmax(te1)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# softmax sums to 1.0\n",
    "s.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 784])\n",
      "tensor([[-0.5376,  1.3717,  0.6831,  ...,  1.9719, -0.6089,  0.4366],\n",
      "        [ 3.8722, -1.6887,  0.8647,  ...,  1.5689,  0.7199, -0.8095],\n",
      "        [ 0.8732,  0.5119,  0.3155,  ..., -1.0118, -0.4362, -0.4794],\n",
      "        [-1.5798, -0.7354,  0.3107,  ..., -0.2928, -0.9529, -0.8576]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 80\n",
    "# emb_size = 6\n",
    "emb_size = 784\n",
    "\n",
    "r_in = nn.Embedding(num_embeddings=vocab_size, embedding_dim=emb_size)\n",
    "new_te1 = torch.LongTensor([12, 8, 5, 0])\n",
    "eout = r_in(new_te1)\n",
    "print(eout.shape)\n",
    "print(eout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4., 5., 6., 7., 8.])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.randint(low=4, high=18, size=(1,4))\n",
    "torch.linspace(3,8,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5798e+00, -7.3538e-01,  3.1068e-01, -4.8963e-01, -1.3874e+00,\n",
       "          7.2356e-02, -1.9512e+00, -2.4721e-02,  1.4559e-01,  8.3897e-02,\n",
       "          2.4256e-01,  8.8669e-01, -1.0295e+00,  1.7729e-01, -7.4582e-01,\n",
       "          2.7761e-01,  1.7317e+00,  7.1764e-01,  2.6918e-01,  5.7215e-01,\n",
       "         -6.8779e-01, -1.3057e-01, -4.6329e-01,  1.7224e+00,  4.7065e-01,\n",
       "          1.6437e+00,  1.6987e+00,  4.6319e-01, -6.3856e-01,  1.5659e+00,\n",
       "         -1.3526e+00, -1.0006e-01,  1.1381e+00,  5.7479e-01,  2.9670e-01,\n",
       "         -2.9718e-01, -1.8556e+00,  1.0386e+00, -7.2160e-01, -2.5542e+00,\n",
       "         -6.6307e-01,  5.9296e-01,  3.3716e-02,  1.1445e+00, -1.0741e+00,\n",
       "          2.6674e-01, -1.1602e+00, -7.8298e-01,  1.8680e+00, -2.3353e-01,\n",
       "         -7.8968e-02,  5.6062e-01, -3.4823e-01,  9.2666e-01, -5.3068e-01,\n",
       "          1.2467e+00, -4.3039e-01,  2.9230e-03, -6.6415e-01,  5.4997e-01,\n",
       "          2.1429e+00, -1.6650e+00,  2.9356e+00,  7.3765e-01, -4.0848e-01,\n",
       "         -2.2729e-01, -3.3998e-01,  1.4207e+00,  1.5974e+00, -7.9570e-01,\n",
       "         -4.6909e-01,  1.7932e+00,  2.2568e-01,  1.0125e+00, -1.2669e-01,\n",
       "         -3.2119e-01,  4.9808e-01,  4.0704e-01, -7.3298e-01,  9.9149e-01,\n",
       "         -1.7322e+00, -2.0850e+00, -1.2993e+00, -9.1417e-01, -1.0902e+00,\n",
       "          7.9402e-01,  7.0557e-01,  1.0798e+00, -1.3035e+00, -3.7930e-01,\n",
       "         -1.2509e+00, -1.3419e+00,  7.1165e-01, -7.6754e-01, -9.0589e-01,\n",
       "         -5.2311e-01, -1.0379e+00, -4.6788e-02,  2.3580e+00,  9.1159e-01,\n",
       "          1.4193e+00,  1.8968e-01, -5.4089e-01, -4.6130e-01,  3.6562e-01,\n",
       "          1.3697e-01,  7.1153e-01, -1.8809e+00, -3.7756e-01,  1.3595e+00,\n",
       "          3.2342e-01,  4.5116e-01,  9.4571e-01, -4.5049e-01,  1.3630e-01,\n",
       "          4.6083e-01, -4.6185e-01,  7.2399e-01,  6.5537e-01, -4.9667e-01,\n",
       "          6.1960e-02,  1.5346e-01, -2.0003e-01,  1.1271e+00,  1.7668e-01,\n",
       "          9.2280e-01, -1.0549e+00, -7.0007e-01, -1.7726e-01, -1.9013e+00,\n",
       "         -2.3896e-01,  1.3431e+00,  1.0745e+00, -1.0971e+00,  6.1195e-01,\n",
       "          5.8501e-01, -1.6886e+00,  9.5838e-01, -1.8734e+00,  9.7882e-01,\n",
       "          6.1080e-02,  1.2500e+00,  3.7718e-01,  6.7359e-01,  6.3252e-01,\n",
       "         -1.1134e+00, -1.1931e+00, -7.8792e-01, -9.2613e-02,  4.4038e-01,\n",
       "          4.1137e-01,  1.0917e+00,  9.6610e-01, -4.7194e-02, -3.1417e-02,\n",
       "          1.2338e+00,  9.1315e-01,  3.4019e-01,  4.7905e-01, -1.5878e+00,\n",
       "          1.2655e-01, -1.1142e-01,  1.3424e+00,  2.4287e-01,  4.9005e-01,\n",
       "          3.7588e-01,  2.9459e-01, -1.4064e+00,  9.0092e-01,  1.3150e+00,\n",
       "         -7.9188e-01,  1.9940e+00,  1.6886e+00,  9.7493e-01,  9.2845e-02,\n",
       "         -1.1485e+00,  2.2534e-03,  3.3820e-01,  7.9059e-01,  7.1543e-01,\n",
       "         -1.1678e+00,  4.8821e-01,  3.1539e-01,  3.5778e-02,  1.2625e+00,\n",
       "         -5.5999e-01, -9.7318e-01,  1.3824e+00, -5.1412e-01, -1.8880e-01,\n",
       "         -1.5268e-01, -1.7961e+00, -2.8060e-01,  7.3278e-01,  3.4110e-01,\n",
       "          9.3963e-01,  2.3417e-02, -2.3516e-01, -7.8027e-01,  9.8176e-01,\n",
       "         -1.1258e+00, -4.4481e-01, -2.8214e+00,  1.4640e-01, -1.2536e+00,\n",
       "          5.0653e-01,  9.2934e-01, -8.5136e-01, -6.7781e-01, -4.5279e-01,\n",
       "          1.1285e+00, -2.3589e-01, -4.4772e-01, -1.5085e+00, -1.6504e+00,\n",
       "          1.3579e+00, -1.2499e+00,  1.2324e-01,  2.4861e-01,  2.2006e-01,\n",
       "          7.1185e-01,  6.3864e-01, -4.9226e-01, -1.1398e-01,  5.8880e-01,\n",
       "          3.2932e-01,  5.8252e-01, -6.0751e-01, -6.3679e-01, -1.1640e+00,\n",
       "          1.3258e+00,  2.0639e+00, -3.8307e-01,  3.5716e-01,  2.9970e-01,\n",
       "          2.2740e+00, -2.9954e-01,  2.5479e-01, -1.0823e-01, -7.5725e-01,\n",
       "         -1.1418e+00, -2.7271e-01, -1.6508e+00,  3.1566e-01, -3.9090e-01,\n",
       "          5.3335e-01,  7.7108e-01,  9.5331e-01,  7.2597e-03, -7.9000e-01,\n",
       "          4.4663e-01, -6.5309e-01,  1.0095e+00,  3.2547e-02, -1.1993e+00,\n",
       "          4.0872e-01,  1.2634e-01, -7.5377e-01,  2.0605e-01, -7.2232e-01,\n",
       "         -1.3744e-01, -6.8864e-02,  2.7036e-01, -2.6466e-01,  5.7515e-01,\n",
       "         -4.7375e-01,  1.4214e+00, -2.2259e-01,  7.7275e-01,  3.0153e-01,\n",
       "         -5.6924e-01,  1.8641e+00,  1.2502e+00, -2.0354e+00, -4.9670e-01,\n",
       "          3.2314e-02,  3.6626e-01,  4.1209e-01, -3.0825e-01,  1.6056e+00,\n",
       "         -9.7688e-01,  8.8182e-01,  1.6317e+00,  7.4821e-01, -1.6248e-01,\n",
       "         -5.9340e-01,  3.5706e-01,  1.8332e+00,  1.6540e-01, -7.1958e-01,\n",
       "         -7.2012e-01, -1.7886e+00,  5.7258e-01,  4.5445e-01,  1.0392e+00,\n",
       "         -5.6911e-01, -5.9394e-01, -2.8493e-01, -8.0285e-01,  8.4124e-01,\n",
       "         -1.0923e-01, -1.2532e+00,  8.4889e-01,  5.9889e-01,  6.5813e-01,\n",
       "          2.7048e-01, -3.2106e-01, -6.2123e-03,  3.0640e-01, -1.2903e-01,\n",
       "         -1.4138e+00,  1.4543e-01,  6.8484e-01,  3.3870e-01, -8.3998e-01,\n",
       "         -1.2890e+00, -2.8961e-01,  1.6868e+00,  1.7075e-03, -3.5869e-02,\n",
       "         -2.8437e-01, -4.5290e-01, -9.5276e-01, -8.6346e-01,  5.6319e-01,\n",
       "          2.7069e-01, -3.1739e-01,  5.6511e-01, -4.2259e-01,  1.1009e+00,\n",
       "          4.5845e-01,  8.6865e-01, -7.8789e-01, -3.5565e-01,  3.3211e-01,\n",
       "         -2.7702e-01, -9.9665e-01,  1.8690e+00,  3.6649e-01, -2.4416e-01,\n",
       "          5.1285e-02,  5.9704e-01, -1.0644e+00, -3.2016e-02, -7.5175e-01,\n",
       "          1.5252e+00, -1.8828e+00,  1.4370e+00, -1.7171e+00, -4.5731e-01,\n",
       "         -6.6280e-01,  9.2217e-01, -1.6248e+00,  8.2062e-01,  1.0383e-01,\n",
       "          1.5196e-01,  9.3118e-01, -6.5906e-01, -2.5223e-01,  2.3676e-01,\n",
       "          6.1426e-01,  1.3610e+00,  1.5012e+00, -4.5249e-01,  2.6301e-01,\n",
       "         -1.1944e+00,  1.7512e+00, -6.4442e-01,  1.1685e+00, -1.4190e-01,\n",
       "         -1.2172e+00,  8.1197e-01, -1.4479e+00,  8.6547e-02, -1.3350e+00,\n",
       "         -2.2450e-01,  2.2177e-01, -3.1223e-01,  4.9536e-01, -9.7664e-01,\n",
       "          2.0760e+00,  1.1209e+00,  9.3147e-02,  9.8703e-01,  7.0998e-01,\n",
       "          8.6881e-01, -1.0279e+00,  4.6197e-01,  1.1558e+00, -2.4806e-01,\n",
       "         -1.0017e+00, -8.2383e-01, -5.6209e-01,  1.3772e+00,  1.4304e-02,\n",
       "         -8.4107e-02, -8.3490e-01,  8.2394e-01, -1.9648e-01, -2.6998e-01,\n",
       "         -1.0695e+00,  1.0309e+00, -2.5859e-01,  8.5035e-01,  3.6666e-01,\n",
       "          7.8531e-01,  1.1046e+00, -5.3644e-02,  1.3539e+00,  2.1557e-02,\n",
       "         -1.4123e+00, -1.5673e+00,  1.2735e+00, -4.6710e-01, -6.0403e-01,\n",
       "          2.4885e-01, -2.7721e+00,  4.8432e-01,  1.1447e+00,  1.6665e+00,\n",
       "         -1.8522e+00,  6.7567e-01,  1.0861e+00,  7.0773e-01,  1.8953e-01,\n",
       "          2.5250e+00,  1.9057e-01,  8.6112e-02,  5.6422e-01,  6.7240e-01,\n",
       "          7.3210e-01, -1.0235e+00, -2.2966e-02,  5.7092e-01,  1.4075e+00,\n",
       "         -2.2096e+00, -1.3632e+00,  8.4324e-01,  1.1203e-01,  7.4629e-02,\n",
       "          1.1987e+00,  8.5584e-01, -1.5671e+00,  1.0038e+00,  2.9630e-01,\n",
       "         -7.3535e-01, -6.1364e-01,  1.0435e+00,  5.0825e-01, -1.7834e-01,\n",
       "         -9.4500e-01, -1.9000e+00,  1.8869e+00,  1.4023e+00, -5.0727e-02,\n",
       "          8.9008e-01,  1.6711e+00,  3.6305e-01,  3.8699e-01, -5.1231e-01,\n",
       "          2.9490e-02, -7.3213e-01,  1.3828e+00,  2.3070e-01, -1.8879e+00,\n",
       "         -2.8938e-02, -2.3797e-01,  2.7565e-01,  1.2884e+00,  1.5115e+00,\n",
       "          1.4732e+00,  1.3220e+00,  9.1220e-01,  2.1862e+00,  3.0438e-01,\n",
       "         -2.5944e-01,  8.9112e-02, -1.6010e+00,  2.0954e+00,  4.6063e-01,\n",
       "          1.8467e+00, -7.0199e-02,  6.0881e-02, -1.4450e+00, -4.8233e-01,\n",
       "         -1.1655e-01,  1.1529e+00,  1.3406e+00,  1.4868e+00, -1.4735e+00,\n",
       "          4.4401e-01,  3.3732e-01,  1.2108e+00,  5.6172e-01, -2.6964e-01,\n",
       "          6.7463e-01, -1.7421e+00,  9.2926e-01, -1.9933e+00, -1.6418e+00,\n",
       "          1.7132e+00,  1.3965e+00,  2.8369e-01,  5.9281e-01,  3.6079e-01,\n",
       "          1.5345e+00, -6.5522e-01, -1.4702e+00, -3.3609e-01, -1.0299e+00,\n",
       "          3.0118e-01, -1.2277e-01, -1.1568e+00, -1.0768e+00,  1.7366e+00,\n",
       "          7.8421e-01, -1.1008e-02,  6.8230e-02,  9.8621e-01, -6.2081e-01,\n",
       "          5.4658e-02, -1.1936e-01,  1.0579e+00, -8.6369e-01, -4.1760e-01,\n",
       "         -1.2099e-01, -4.6811e-01,  1.8874e-01, -4.9074e-01,  6.0738e-02,\n",
       "          1.4428e+00, -4.5183e-01, -1.0046e+00, -1.1592e+00, -9.8852e-01,\n",
       "         -6.0473e-02, -2.2253e-01, -6.0401e-01, -1.6609e-01,  1.0717e+00,\n",
       "         -2.6338e-01,  1.5449e-01,  1.7910e-01, -4.1915e-01,  2.0426e+00,\n",
       "          1.1736e+00,  3.6369e-01, -1.4671e+00,  6.8110e-01,  1.5344e+00,\n",
       "          5.7003e-01,  5.9807e-01,  5.1773e-02,  3.9170e-01, -4.6712e-01,\n",
       "          4.7661e-01,  3.9027e-01,  1.7564e-02, -4.0064e-01,  2.1017e+00,\n",
       "          9.4174e-01, -9.8865e-01, -1.0004e+00,  1.8155e+00, -1.3303e+00,\n",
       "          4.3263e-01, -5.3489e-01,  9.8603e-01, -2.7254e-01,  2.1566e+00,\n",
       "          1.0888e-01, -2.8882e-01,  1.0481e+00, -5.4816e-01, -1.5692e+00,\n",
       "          2.3456e-01,  1.0022e+00, -2.9167e-01, -1.8202e+00,  1.5213e+00,\n",
       "          1.4121e+00, -2.0574e+00,  1.0483e+00, -1.7010e-01,  8.1155e-02,\n",
       "         -2.2249e-01, -1.1566e+00, -2.0617e+00,  2.8564e-01, -8.2864e-01,\n",
       "          3.3013e-01,  1.7573e+00,  1.0839e+00, -9.6794e-01,  7.1745e-01,\n",
       "         -1.1966e+00, -1.2373e+00,  2.2753e-01, -1.6471e+00,  7.6475e-01,\n",
       "          1.9707e+00,  8.8261e-01,  1.3141e+00, -3.6279e-01,  1.5127e-01,\n",
       "          8.9301e-01,  6.7979e-01, -3.2463e-01,  3.3743e-01,  5.4671e-01,\n",
       "          8.5226e-01,  6.0534e-01,  4.3446e-01,  1.2206e+00, -5.2716e-01,\n",
       "         -6.2457e-01,  1.4507e+00,  1.0113e-01,  1.0329e+00,  7.1316e-02,\n",
       "          4.4804e-02,  1.0867e+00, -9.8073e-01,  1.8244e+00, -2.4744e-01,\n",
       "         -1.3244e+00, -1.1481e+00,  1.6271e+00,  7.7736e-01, -7.0745e-02,\n",
       "          9.9474e-01, -1.0816e+00, -1.7104e+00,  4.5268e-01, -1.3153e+00,\n",
       "         -5.3661e-01,  9.4396e-01, -9.5432e-01,  1.4062e-01, -2.5047e+00,\n",
       "          2.7510e-01, -7.5444e-01, -1.3223e+00,  7.8644e-01,  3.8369e-01,\n",
       "         -3.3551e-01, -1.4233e+00,  4.5729e-01, -8.1616e-01, -1.2960e+00,\n",
       "         -6.6961e-01,  8.8367e-01,  6.6347e-01,  9.4666e-01,  2.7835e-01,\n",
       "         -6.9106e-01,  1.7679e+00, -3.9559e-01, -3.7927e-01,  9.5471e-01,\n",
       "          4.3233e-01,  4.2230e-01, -1.7238e-01,  1.0307e+00,  1.3587e+00,\n",
       "         -4.3923e-02,  4.7677e-01, -1.2749e+00, -5.8786e-01, -1.1537e+00,\n",
       "         -4.2667e-01, -8.8607e-01, -4.6753e-01, -8.2690e-01,  1.4817e+00,\n",
       "          2.2955e-01,  6.7201e-02,  1.6196e-01, -1.1376e-01,  1.5694e-01,\n",
       "          8.3385e-01, -1.0011e+00, -1.8619e-01,  1.1635e+00, -1.3579e+00,\n",
       "          8.0630e-01, -1.7450e+00, -7.4394e-01,  1.9413e+00,  6.5028e-02,\n",
       "          1.8225e-01, -8.6134e-01,  5.5711e-01,  1.4887e+00,  5.0248e-02,\n",
       "          2.3870e-01, -1.5791e+00,  2.8146e-01,  1.1291e-01,  8.7742e-01,\n",
       "          6.3837e-01,  4.9625e-01, -2.0080e-01,  5.3435e-01,  3.6906e-01,\n",
       "         -2.6869e-01,  8.4629e-01,  9.5844e-01,  8.6687e-01, -1.1497e+00,\n",
       "          7.8566e-01, -3.6995e-01, -1.0380e+00,  5.0161e-02, -1.0841e+00,\n",
       "         -1.6681e-01, -1.8557e+00, -1.8685e-01, -1.7365e+00, -1.8822e+00,\n",
       "         -6.7203e-01,  1.5152e+00,  8.3907e-01, -7.8524e-02, -1.1913e+00,\n",
       "          1.0474e+00, -9.2855e-01,  1.6123e+00,  1.3441e+00, -7.2202e-01,\n",
       "         -7.2592e-01, -5.2581e-01,  7.0896e-01, -1.3574e+00,  5.4212e-01,\n",
       "         -1.8384e+00, -7.0121e-01,  4.6491e-01, -1.1771e-01, -6.2181e-01,\n",
       "          7.5540e-01,  7.0390e-01,  9.2039e-01, -5.0104e-02,  6.6887e-01,\n",
       "         -2.5603e-01, -1.1741e+00, -6.9315e-01,  1.1872e+00,  3.0300e-01,\n",
       "          1.1210e-01,  7.3885e-01,  7.5884e-01, -2.4103e-01, -2.2604e-01,\n",
       "         -1.3950e+00,  1.0420e+00,  8.8663e-01,  1.1897e+00,  2.6647e+00,\n",
       "         -3.0910e-01, -9.9007e-01,  2.0593e-02,  8.8154e-01, -6.8386e-01,\n",
       "         -4.5185e-01,  1.8324e-01,  1.2814e+00,  1.7533e+00, -1.0215e+00,\n",
       "         -1.1267e+00, -9.0398e-01,  6.1322e-01, -3.7695e-01, -1.1434e+00,\n",
       "          4.3826e-01,  4.6641e-03,  1.0316e-01,  2.6191e-01, -3.8916e-01,\n",
       "         -4.3083e-01, -2.9279e-01, -9.5294e-01, -8.5761e-01]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1 = torch.tensor([0], dtype =torch.int32)\n",
    "ex1\n",
    "outp=r_in(ex1)\n",
    "outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertTokenizerFast(name_or_path='distilbert/distilbert-base-uncased-finetuned-sst-2-english', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert/distilbert-base-uncased-finetuned-sst-2-english')\n",
    "vocab_size_distilber=30522\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 384)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_emb = nn.Embedding(num_embeddings = vocab_size_distilber, embedding_dim=384)\n",
    "db_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 2057, 2024, 5604, 7861, 8270, 4667, 2015, 2005, 1996, 2034, 2051,\n",
      "          102]])\n"
     ]
    }
   ],
   "source": [
    "sent = \"we are testing embeddings for the first time\"\n",
    "sent_tokens = tokenizer(sent, return_tensors='pt')\n",
    "print(sent_tokens['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6918, -1.9705,  0.3291,  ..., -0.7998, -3.1324,  0.2211],\n",
       "         [-0.8938,  1.6910,  0.1237,  ..., -0.1077,  1.3064,  0.0846],\n",
       "         [-0.4536,  0.9506, -1.0150,  ...,  1.0822, -0.2433, -0.0779],\n",
       "         ...,\n",
       "         [-0.1170, -0.0227,  1.0186,  ...,  2.0562, -0.0242,  0.6398],\n",
       "         [-0.0716, -0.1697, -0.4133,  ...,  1.2634, -0.0077, -0.9388],\n",
       "         [ 0.2548,  0.5899,  1.7038,  ...,  0.4848, -0.3463, -0.5861]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_emb(sent_tokens['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a data set and use mapping to create embeddings and compare without mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 4, 5, 6, 7, 8], dtype=torch.int32)\n",
      "torch.Size([6, 6])\n",
      "tensor([[ 2.0871,  0.2693, -0.2372, -0.7070,  1.4054,  0.5916],\n",
      "        [-1.9891,  0.6110, -0.4201, -1.6939,  0.2827,  0.6559],\n",
      "        [-1.4677,  0.0138, -0.7707, -1.0284, -0.2682, -0.2340],\n",
      "        [-1.8330,  0.2829,  0.3154,  0.5179, -0.9329,  1.4112],\n",
      "        [-0.0701,  0.3991, -0.7764, -1.2926, -2.4103, -0.1897],\n",
      "        [ 1.0619, -0.7392,  0.4594, -0.6055, -1.0341,  0.2355]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "new_te2 = torch.linspace(3,8,6, dtype=torch.int)\n",
    "print(new_te2)\n",
    "eout2 = r_in(new_te2)\n",
    "print(eout2.shape)\n",
    "print(eout2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19, 12, 10],\n",
      "        [32, 21, 16],\n",
      "        [45, 30, 22],\n",
      "        [58, 39, 28]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "b = torch.tensor([[7, 6, 2], [6, 3, 4]])\n",
    "\n",
    "print(a @ b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3 8\n",
      "torch.Size([6, 8])\n"
     ]
    }
   ],
   "source": [
    "input = torch.rand(2,3,8)\n",
    "\n",
    "n,r,c = input.shape\n",
    "print(n,r,c)\n",
    "output = input.view(n*r,c)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2169, 0.7580, 0.4977, 0.6913, 0.9418, 0.9474, 0.4893, 0.4242],\n",
      "         [0.7699, 0.0595, 0.1064, 0.5097, 0.2571, 0.4381, 0.1050, 0.7029],\n",
      "         [0.2340, 0.7783, 0.2890, 0.1575, 0.0092, 0.3530, 0.0209, 0.0807]],\n",
      "\n",
      "        [[0.4697, 0.7373, 0.4587, 0.5898, 0.1385, 0.5877, 0.7840, 0.6525],\n",
      "         [0.5178, 0.5769, 0.3043, 0.5954, 0.3512, 0.4245, 0.2480, 0.0374],\n",
      "         [0.5843, 0.8717, 0.9643, 0.5455, 0.3535, 0.9158, 0.7526, 0.6518]]])\n",
      "tensor([[0.2169, 0.7580, 0.4977, 0.6913, 0.9418, 0.9474, 0.4893, 0.4242],\n",
      "        [0.7699, 0.0595, 0.1064, 0.5097, 0.2571, 0.4381, 0.1050, 0.7029],\n",
      "        [0.2340, 0.7783, 0.2890, 0.1575, 0.0092, 0.3530, 0.0209, 0.0807],\n",
      "        [0.4697, 0.7373, 0.4587, 0.5898, 0.1385, 0.5877, 0.7840, 0.6525],\n",
      "        [0.5178, 0.5769, 0.3043, 0.5954, 0.3512, 0.4245, 0.2480, 0.0374],\n",
      "        [0.5843, 0.8717, 0.9643, 0.5455, 0.3535, 0.9158, 0.7526, 0.6518]])\n"
     ]
    }
   ],
   "source": [
    "print(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[44, 18, 61, 53, 40, 65, 43, 26],\n",
      "        [16, 53,  5, 39, 70, 45, 44, 31]])\n",
      "tensor([[39, 74, 70, 47, 32, 74, 45, 65],\n",
      "        [63, 72, 25, 45, 70, 44, 27, 57]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.randint(1, 75, size=(2, 8))\n",
    "d = torch.randint(1, 75, size=(2, 8))\n",
    "print(b)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[51., 27., 26., 46., 26.,  4., 62.,  7.],\n",
      "        [42.,  4.,  5., 27., 48., 24., 53., 10.]])\n",
      "tensor([[19., 69., 52., 72., 58., 29.,  2., 13.],\n",
      "        [34., 24., 70.,  9.,  9.,  9., 18., 26.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m_/_x8t4kvn0334z53zdz_86l400000gp/T/ipykernel_33977/781537471.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  b = torch.tensor(torch.randint(1, 75, size=(2, 8)), dtype=torch.float32)\n",
      "/var/folders/m_/_x8t4kvn0334z53zdz_86l400000gp/T/ipykernel_33977/781537471.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  d = torch.tensor(torch.randint(1, 75, size=(2, 8)), dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "b = torch.tensor(torch.randint(1, 75, size=(2, 8)), dtype=torch.float32)\n",
    "d = torch.tensor(torch.randint(1, 75, size=(2, 8)), dtype=torch.float32) \n",
    "print(b)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = b.float() \n",
    "bf.dtype\n",
    "df = d.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([19., 69., 52., 72., 58., 29.,  2., 13., 34., 24., 70.,  9.,  9.,  9.,\n",
       "        18., 26.])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.view(2 * 8)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18492.0723)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce = F.cross_entropy(bf.view(16), df.view(16))\n",
    "ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils._bunch.Bunch'>\n",
      "(178, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(178,)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "wineds = datasets.load_wine()\n",
    "# print(wineds.shape)\n",
    "print(type(wineds))\n",
    "data = wineds['data']\n",
    "print(data.shape)\n",
    "tgt = wineds['target']\n",
    "tgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "<class 'numpy.ndarray'>\n",
      "target\n",
      "<class 'numpy.ndarray'>\n",
      "frame\n",
      "<class 'NoneType'>\n",
      "target_names\n",
      "<class 'numpy.ndarray'>\n",
      "DESCR\n",
      "<class 'str'>\n",
      "feature_names\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "for i,x in wineds.items():\n",
    "    print(i)\n",
    "    print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data from sklearn datasets, shape 178,13==> dict==> with data and tgt\n",
    "# convert the data from numpy to tensors torch using class Winedataset which inherits datasets class from torch.utils.data\n",
    "# load the dataset using dataloader with batch size = 3\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250,)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_data = np.linspace(50, 686, 250)\n",
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor = torch.from_numpy(x_data.astype(np.float32))\n",
    "x_tensor.shape\n",
    "x_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x = torch.from_numpy(x_data.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y_data.astype(np.float32))\n",
    "        self.n_samples = x_data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.3160e+01, 2.3600e+00, 2.6700e+00, 1.8600e+01, 1.0100e+02, 2.8000e+00,\n",
       "         3.2400e+00, 3.0000e-01, 2.8100e+00, 5.6800e+00, 1.0300e+00, 3.1700e+00,\n",
       "         1.1850e+03]),\n",
       " tensor(0.))"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineds = WineDataset(x_data=data,\n",
    "                     y_data=tgt)\n",
    "wineds[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_dl = DataLoader(wineds, shuffle=True, batch_size=3)\n",
    "dloader_iter = iter(wine_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1.2000e+01, 3.4300e+00, 2.0000e+00, 1.9000e+01, 8.7000e+01, 2.0000e+00,\n",
       "          1.6400e+00, 3.7000e-01, 1.8700e+00, 1.2800e+00, 9.3000e-01, 3.0500e+00,\n",
       "          5.6400e+02],\n",
       "         [1.3390e+01, 1.7700e+00, 2.6200e+00, 1.6100e+01, 9.3000e+01, 2.8500e+00,\n",
       "          2.9400e+00, 3.4000e-01, 1.4500e+00, 4.8000e+00, 9.2000e-01, 3.2200e+00,\n",
       "          1.1950e+03],\n",
       "         [1.3050e+01, 2.0500e+00, 3.2200e+00, 2.5000e+01, 1.2400e+02, 2.6300e+00,\n",
       "          2.6800e+00, 4.7000e-01, 1.9200e+00, 3.5800e+00, 1.1300e+00, 3.2000e+00,\n",
       "          8.3000e+02]]),\n",
       " tensor([1., 0., 0.])]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(dloader_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.empty(5,6,7)\n",
    "y = torch.empty(5,6,7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.empty((0, ))\n",
    "x = torch.empty(2, 2)\n",
    "\n",
    "a = torch.rand((3, 3, 1))\n",
    "b = torch.rand((3, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor of same shapes are broadcastable\n",
    "# Broadcastable ??\n",
    "\n",
    "# In above example tensor T2 shape (3,1) has one in its back dimension and tension T1 (3,3) don’t have any one in its dimension . \n",
    "# So, We have to broadcast along the dimension where the tensor dimension is 1 to match the corresponding dimension of the other tensor T1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7755)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When it comes to Matrix Multiplication, there are following pairs one has to identify\n",
    "# vector * vector, matrix * vector, batched mat * vector(bc) \n",
    "# batched matrix * batched matrix, batched matrix * broadcasted matrix\n",
    "# A vector is of shape 1 row n col\n",
    "\n",
    "# vector X vector is acceptable, and return dot product\n",
    "tensor2 = torch.rand(3)  # Size([3]) \n",
    "\n",
    "tensor1 = torch.tensor([5, 6, 8], dtype=torch.float32)  # Size([3])\n",
    "\n",
    "tensor1 @ tensor2  # returns dot-pdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.6682, 5.3502, 6.5811])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matensor = torch.tensor([[1, 3, 4,],\n",
    "                         [5, 7, 6,],\n",
    "                         [9, 2, 8]],\n",
    "                         dtype=torch.float32)\n",
    "\n",
    "tensor2 @ matensor  # 1D to 2D is processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4579, 0.6261, 0.6651],\n",
       "        [0.5829, 0.3901, 0.2865],\n",
       "        [0.3877, 0.5067, 0.1535]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor5 = torch.rand(3, 3, 4)\n",
    "tensor6 = torch.rand(4)\n",
    "\n",
    "tensor5 @ tensor6 # batched tensor broadcasts over vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.8014, 0.0525, 0.9832],\n",
      "         [0.4184, 0.2516, 0.4690],\n",
      "         [0.1283, 0.0737, 0.4402]],\n",
      "\n",
      "        [[0.5293, 0.2953, 0.0341],\n",
      "         [0.7695, 0.8032, 0.2560],\n",
      "         [0.6585, 0.3636, 0.9774]]])\n",
      "tensor([[[1.2398, 1.2223, 0.7674],\n",
      "         [0.7292, 0.6151, 0.4099],\n",
      "         [0.4932, 0.4500, 0.3372]],\n",
      "\n",
      "        [[0.6754, 0.7720, 0.5152],\n",
      "         [1.3437, 1.5441, 1.0777],\n",
      "         [1.5373, 1.4577, 1.4480]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor7 = torch.rand(2,3,3)\n",
    "tensor8 = torch.rand(2,3,3)\n",
    "print(tensor7)\n",
    "print(tensor7 @ tensor8)\n",
    "(tensor7 @ tensor8).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([18])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten = nn.Flatten(start_dim=0, end_dim=-1)\n",
    "print(tensor8.shape)\n",
    "x = flatten(tensor8)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten = nn.Flatten(start_dim=0, end_dim=-2)\n",
    "print(tensor8.shape)\n",
    "x = flatten(tensor8)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 784])\n"
     ]
    }
   ],
   "source": [
    "flaten = nn.Flatten(start_dim=1, end_dim=-1)\n",
    "# -1 means the final value is calculated by torch\n",
    "test_data2 = torch.rand(5, 28, 28)\n",
    "test_out = flaten(test_data2)  # Size([5, 784])\n",
    "\n",
    "print(test_out.shape)  # Size([5, 784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0887, -0.5747],\n",
       "        [-0.0456, -0.5921],\n",
       "        [-0.2420, -0.4732],\n",
       "        [-0.1538, -0.2757],\n",
       "        [ 0.0569, -0.3440]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = nn.Linear(784, 2)\n",
    "l1(test_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0569, 0.0000]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = nn.ReLU()\n",
    "hi2 = r1(l1(test_out))\n",
    "hi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0511,  0.0473,  0.0584,  0.0043,  0.0442, -0.0790, -0.0265,  0.0521,\n",
       "          0.0805,  0.0394],\n",
       "        [-0.0152,  0.0296,  0.0661,  0.0006,  0.0241, -0.0941, -0.0817,  0.0735,\n",
       "          0.1138,  0.0345],\n",
       "        [-0.0289,  0.0015,  0.0601,  0.0128, -0.0128, -0.1033, -0.0774,  0.0901,\n",
       "          0.0806,  0.0221],\n",
       "        [-0.0425, -0.0035,  0.0678,  0.0234,  0.0340, -0.1007, -0.0246,  0.0715,\n",
       "          0.0536,  0.1009],\n",
       "        [-0.0608,  0.0428,  0.1092, -0.0086,  0.0071, -0.1028, -0.0586,  0.1175,\n",
       "          0.0768,  0.0307]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2 = nn.Sequential(\n",
    "    flaten,\n",
    "    nn.Linear(784, 512),\n",
    "    r1,\n",
    "    nn.Linear(512, 512),\n",
    "    r1,\n",
    "    nn.Linear(512, 10)\n",
    ")\n",
    "print(seq2(test_out).shape)\n",
    "seq2(test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 1.weight | size: torch.Size([512, 784]) | vals : tensor([[-0.0096, -0.0342,  0.0141,  ...,  0.0002,  0.0021,  0.0152],\n",
      "        [-0.0066,  0.0160,  0.0076,  ..., -0.0033,  0.0058,  0.0074]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Layer: 1.bias | size: torch.Size([512]) | vals : tensor([0.0300, 0.0025], grad_fn=<SliceBackward0>)\n",
      "Layer: 3.weight | size: torch.Size([512, 512]) | vals : tensor([[ 0.0116,  0.0386,  0.0078,  ...,  0.0205,  0.0296, -0.0076],\n",
      "        [ 0.0204, -0.0284, -0.0371,  ...,  0.0164, -0.0263, -0.0039]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Layer: 3.bias | size: torch.Size([512]) | vals : tensor([0.0222, 0.0004], grad_fn=<SliceBackward0>)\n",
      "Layer: 5.weight | size: torch.Size([10, 512]) | vals : tensor([[-0.0069, -0.0055,  0.0401,  ...,  0.0275, -0.0219,  0.0047],\n",
      "        [-0.0423,  0.0417, -0.0045,  ...,  0.0125, -0.0406, -0.0157]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Layer: 5.bias | size: torch.Size([10]) | vals : tensor([ 0.0335, -0.0118], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for name, params in seq2.named_parameters():\n",
    "    print(f'Layer: {name} | size: {params.size()} | vals : {params[:2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7658, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "The z grad fn: <AddBackward0 object at 0x7fd8c8812730>\n",
      "The loss grad fn: <BinaryCrossEntropyWithLogitsBackward0 object at 0x7fd8c87a1d60>\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Basic model (need to practice)\n",
    "x = torch.ones(5)\n",
    "y = torch.zeros(3)\n",
    "\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "\n",
    "z = torch.matmul(x, w) + b\n",
    "\n",
    "loss = F.binary_cross_entropy_with_logits(z, y)\n",
    "print(loss)\n",
    "\n",
    "print(f\"The z grad fn: {z.grad_fn}\")\n",
    "print(f\"The loss grad fn: {loss.grad_fn}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    a = torch.matmul(x, w) + b\n",
    "print(z.requires_grad)  # returns False\n",
    "\n",
    "f = torch.matmul(x, w) + b\n",
    "f_det = f.detach()\n",
    "print(f_det.requires_grad)  # returns false"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
