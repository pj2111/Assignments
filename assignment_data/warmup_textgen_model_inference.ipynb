{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "Pix8elC8JEVL",
      "metadata": {
        "id": "Pix8elC8JEVL"
      },
      "outputs": [],
      "source": [
        "!pip install rich transformers torch accelerate bitsandbytes peft > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "301491de",
      "metadata": {
        "id": "301491de"
      },
      "source": [
        "Task: Text Generation\n",
        "\n",
        "Each task has its own default model in the pipeline.\n",
        "\n",
        "- Causal Language Modeling\n",
        "\n",
        "- Masked Language Modeling\n",
        "\n",
        "Another type of variation is\n",
        "\n",
        "- Text Generation\n",
        "\n",
        "- Text-to-Text Generation models\n",
        "\n",
        "\n",
        "Variety of LMs in HuggingFace\n",
        "\n",
        "https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard\n",
        "\n",
        "\n",
        "Some of the Text generation Tasks\n",
        "\n",
        "Code Generation: Trained to generate code\n",
        "\n",
        "https://huggingface.co/spaces/bigcode/bigcode-playground\n",
        "\n",
        "Instruction Model: Those that are trained on instruction\n",
        "\n",
        "Stories generation: A prompt starts the Stories Generation\n",
        "\n",
        "\n",
        "Quantization Using BitsAndBytes is touched\n",
        "\n",
        "- Grokking how the models are shrunk and loaded.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "708f972a-4ac4-4b85-a1aa-a0c2579df219",
      "metadata": {
        "id": "708f972a-4ac4-4b85-a1aa-a0c2579df219"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UXgTZEt23Rt6",
      "metadata": {
        "id": "UXgTZEt23Rt6"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "path = \"distilbert/distilgpt2\"\n",
        "\n",
        "generator = pipeline('text-generation',\n",
        "                     model = path)\n",
        "\n",
        "generator(\"Hello, I'm a language model\",\n",
        "          max_length = 30,\n",
        "          num_return_sequences=3)\n",
        "\n",
        "# Will provide 3 generated statements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4dee59a-9963-43f1-80ce-2e084b5a62e2",
      "metadata": {
        "id": "b4dee59a-9963-43f1-80ce-2e084b5a62e2"
      },
      "outputs": [],
      "source": [
        "# - Text-to-Text generation models have a separate pipeline called text2text-generation.\n",
        "\n",
        "# - This pipeline takes an input containing the sentence including the task and returns the output of the accomplished task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b0ee9b6-54ca-4b5f-aa8d-0bca5ca97bb2",
      "metadata": {
        "id": "5b0ee9b6-54ca-4b5f-aa8d-0bca5ca97bb2"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "text2text_generator = pipeline(\"text2text-generation\")\n",
        "\n",
        "text2text_generator(\"question: What is 42 ? context: 42 is the answer to life, the universe and everything\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lZch88i_yjDZ",
      "metadata": {
        "id": "lZch88i_yjDZ"
      },
      "source": [
        "#### How pipeline works: Dive into AutoClasses\n",
        "\n",
        "The pipeline function is built using the AutoModel, AutoTokenizer to create the generated text. We will look into, how it could be implemented"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "73ccce0e-f9fe-4497-87de-ea684957a9ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73ccce0e-f9fe-4497-87de-ea684957a9ca",
        "outputId": "b82ddd79-bf9b-4796-d47e-f647cb8c6162"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GenerationConfig {\n",
              "  \"bos_token_id\": 50256,\n",
              "  \"eos_token_id\": 50256\n",
              "}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(path)\n",
        "model.generation_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "BhNWnctM80nI",
      "metadata": {
        "id": "BhNWnctM80nI"
      },
      "outputs": [],
      "source": [
        "prompt = \"Question: Please write a function in Python that transforms bytes to Giga bytes.\\n\\nAnswer:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "gOa1sxiE0cmX",
      "metadata": {
        "id": "gOa1sxiE0cmX"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "z9wdhcjt0eCA",
      "metadata": {
        "id": "z9wdhcjt0eCA"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(path,\n",
        "                                             pad_token_id=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "T5pYvaYn7Lqm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "T5pYvaYn7Lqm",
        "outputId": "26fe338c-65cd-4640-a424-1508a98b88b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' \"Giga bytes are defined by the Python module in src/giga.py.\\nIf you are using the interpreter in python 2 or above please note in the corresponding module that it\\'s compiled in the \"GigaBytes.py\" folder.'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Lets first look at how to provide the model into the pipeline\n",
        "\n",
        "pipe = pipeline(\"text-generation\",\n",
        "                model=model,\n",
        "                tokenizer=tokenizer)\n",
        "\n",
        "result = pipe(prompt,\n",
        "              max_new_tokens=60)[0][\"generated_text\"][len(prompt):]\n",
        "\n",
        "result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K_3mEXi_1r7W",
      "metadata": {
        "id": "K_3mEXi_1r7W"
      },
      "outputs": [],
      "source": [
        "# max_new_tokens: the maximum number of tokens to generate. In other words, the size of the output sequence,\n",
        "# not including the tokens in the prompt. As an alternative to using the output’s length as a stopping criteria,\n",
        "# you can choose to stop generation whenever the full generation exceeds some amount of time. To learn more, check StoppingCriteria.\n",
        "\n",
        "# num_beams: by specifying a number of beams higher than 1, you are effectively switching from greedy\n",
        "# search to beam search. This strategy evaluates several hypotheses at each time step and eventually\n",
        "# chooses the hypothesis that has the overall highest probability for the entire sequence. This has\n",
        "# the advantage of identifying high-probability sequences that start with a lower probability initial\n",
        "# tokens and would’ve been ignored by the greedy search. Visualize how it works in the beam search visualizer below.\n",
        "\n",
        "# do_sample: if set to True, this parameter enables decoding strategies such as multinomial sampling,\n",
        "# beam-search multinomial sampling, Top-K sampling and Top-p sampling. All these strategies select the\n",
        "# next token from the probability distribution over the entire vocabulary with various strategy-specific adjustments.\n",
        "\n",
        "# num_return_sequences: the number of sequence candidates to return for each input. This option is only\n",
        "# available for the decoding strategies that support multiple sequence candidates, e.g. variations of\n",
        "# beam search and sampling. Decoding strategies like greedy search and contrastive search\n",
        "# return a single output sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZvNnoZRo1yS_",
      "metadata": {
        "id": "ZvNnoZRo1yS_"
      },
      "outputs": [],
      "source": [
        "# https://huggingface.co/spaces/m-ric/beam_search_visualizer\n",
        "\n",
        "# https://huggingface.co/blog/optimize-llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "puR0uNDT18OH",
      "metadata": {
        "id": "puR0uNDT18OH"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, GenerationConfig\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-small\")\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google-t5/t5-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5Xm5n5pY9-_m",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "5Xm5n5pY9-_m",
        "outputId": "911a9c3c-0829-40f0-f437-7ec888977373"
      },
      "outputs": [],
      "source": [
        "translation_generation_config = GenerationConfig(\n",
        "    num_beams=4,\n",
        "    early_stopping=True,\n",
        "    decoder_start_token_id=0,\n",
        "    eos_token_id=model.config.eos_token_id,\n",
        "    pad_token=model.config.pad_token_id,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2Qw1jOy51bIP",
      "metadata": {
        "id": "2Qw1jOy51bIP"
      },
      "outputs": [],
      "source": [
        "# Tip: add `push_to_hub=True` to push to the Hub\n",
        "translation_generation_config.save_pretrained(\"/tmp\", \"translation_generation_config.json\")\n",
        "\n",
        "# You could then use the named generation config file to parameterize generation\n",
        "generation_config = GenerationConfig.from_pretrained(\"/tmp\", \"translation_generation_config.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cuMmmcbQ3Ju4",
      "metadata": {
        "id": "cuMmmcbQ3Ju4"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer(\"translate English to French: Configuration files are easy to use!\", return_tensors=\"pt\")b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xmDfxP113LIg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmDfxP113LIg",
        "outputId": "200dede3-9af1-4570-e2f0-2bfd5d6e136c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[13959,  1566,    12,  2379,    10, 25306,   257,  2073,    33,   514,\n",
              "            12,   169,    55,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Sls7uV2Q1i0f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sls7uV2Q1i0f",
        "outputId": "2a12c7e9-7b56-4bc2-a2ef-bbe526fc6243"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Les fichiers de configuration sont faciles à utiliser!']\n"
          ]
        }
      ],
      "source": [
        "outputs = model.generate(**inputs, generation_config=generation_config)\n",
        "\n",
        "print(tokenizer.batch_decode(outputs, skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Lal4vbDy70V7",
      "metadata": {
        "id": "Lal4vbDy70V7"
      },
      "source": [
        "##### Practice with Gemma Model\n",
        "\n",
        "Explore the model inference processes, its methods by executing below cells later the decoding strategies will be explored.\n",
        "\n",
        "##### All the decoding stategies\n",
        "\n",
        "https://huggingface.co/blog/how-to-generate\n",
        "\n",
        "https://huggingface.co/docs/transformers/generation_strategies\n",
        "\n",
        "Greedy Search\n",
        "\n",
        "Contrastive Search\n",
        "\n",
        "Multinomial Sampling\n",
        "\n",
        "Beam-Search Decoding\n",
        "\n",
        "Beam-Search Multinomial Sampling\n",
        "\n",
        "Diverse Beam Search Decoding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yQLdd7xV5c-n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "4f23d01d0377467fbdddeecdab3cdf2f",
            "69db9bc1710149fbbd2064bcf6c0a357",
            "40b2768dcae4413b87fc3104226a0ba6",
            "c176f814672c4c7f9d3e4e881bc3efc6",
            "43829a01fe2a41c490970da1eab4b57d",
            "e7d8be877e984fc4abf0f1d82b65741e",
            "4a739a12768e400195b24516e2db404d",
            "e34ab5d240024f2bae0a7efe0c639219",
            "a5ef08e584c3465d908969fc492bfc94",
            "1769334add064b759d44cd1033111a5f",
            "9d9d8555fcf74673b4687da0e996aff4",
            "243f3efafa0b4c74a2b34efb4b2fb0ef",
            "051ece87c7114977b625fecf6dc58fef",
            "89e8e0e7dc6044f0b7190e98ff4d8f2a",
            "a3b89d21ff5d4e9a86caf5cc79466116",
            "ce942d6a006d49ba90f373adbd39ab19",
            "32ad20d4341947b4b35b78b4bf43a4a1",
            "5fa96886885d493b952f59f6e188376e",
            "c8f74d3de54c4696ade2588c22558499",
            "beb2f40cae28480ba6232b815b51893f",
            "dda0f4e7855a402e9cd0c15ef97c9b6f",
            "2dc102125cf9483bbab9fbf236ee2c7d",
            "69f6ddd5d34541358c5caa1c2098ac85",
            "6a7a7a83b24c4698b870fe6cdc22c588",
            "93582d2c32944b10b78084dd8238a204",
            "459ad13ac99d4e3ca0888767e58ebc35",
            "8b9d3353b9f440c191e9fe2c10918cf8",
            "3027ed173a1f4b6282e48eb54d6d6d55",
            "3621c00d4d014b6d96f350b81f439833",
            "c7488ab5aec249078ec496dab7766a6f",
            "4fd12728c80e4bc5a692feacc348212c",
            "51f6852da42b4ff4aeb1e507a91e5f1b"
          ]
        },
        "id": "yQLdd7xV5c-n",
        "outputId": "5b6f9294-38a4-40c4-9a87-f6516a55b789"
      },
      "outputs": [],
      "source": [
        "# Gemma model will require your read access token.\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Emh1nF6g5xug",
      "metadata": {
        "id": "Emh1nF6g5xug"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b-it\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"google/gemma-2b-it\",\n",
        "    torch_dtype=torch.bfloat16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dvnItdci6LUH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvnItdci6LUH",
        "outputId": "994aa002-8377-47e1-b20d-891319e2a1da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vukt2vUn6VlX",
      "metadata": {
        "id": "vukt2vUn6VlX"
      },
      "outputs": [],
      "source": [
        "model.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8ae303e-50c9-4f81-a655-cc0653007b7d",
      "metadata": {
        "id": "d8ae303e-50c9-4f81-a655-cc0653007b7d"
      },
      "outputs": [],
      "source": [
        "# not required to run this cell.\n",
        "\n",
        "# llama_path = \"/home/kamal/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/c1b0db933684edbfe29a06fa47eb19cc48025e93/\"\n",
        "import torch\n",
        "gemma_path = \"google/gemma-2b-it\"\n",
        "\n",
        "gemma = AutoModelForCausalLM.from_pretrained(\n",
        "    # pretrained_model_name_or_path='/home/aicoder/.cache/huggingface/hub/models--google--gemma-2b-it/snapshots/718cb189da9c5b2e55abe86f2eeffee9b4ae0dad/\n",
        "    gemma_path,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    # local_files_only=True  # this will stop the function from calling the hub for the model\n",
        ") # takes 11GB of VRAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MaML_vAB6n6q",
      "metadata": {
        "id": "MaML_vAB6n6q"
      },
      "outputs": [],
      "source": [
        "from rich import print"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c37fe38-1b2c-4983-ae46-032c66467788",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "5c37fe38-1b2c-4983-ae46-032c66467788",
        "outputId": "1eef16e7-05a6-4f90-d4bb-7fc8367f55f9",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>% for message in messages %<span style=\"font-weight: bold\">}{{</span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;|im_start|&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\"> + message</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\"> + '</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">' + message['</span><span style=\"color: #000000; text-decoration-color: #000000\">content'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\"> + </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;|im_end|&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\"> + '</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">'}}{% endfor %}{% if add_generation_prompt %}{{ '</span><span style=\"color: #000000; text-decoration-color: #000000\">&lt;|im_start|</span><span style=\"font-weight: bold\">&gt;</span>assistant\n",
              "' <span style=\"font-weight: bold\">}}{</span>% endif %<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m{\u001b[0m% for message in messages %\u001b[1m}\u001b[0m\u001b[1m{\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'\u001b[0m\u001b[32m<\u001b[0m\u001b[32m|im_start|\u001b[0m\u001b[32m>'\u001b[0m\u001b[39m + message\u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'role'\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m + '\u001b[0m\n",
              "\u001b[32m' + message\u001b[0m\u001b[32m[\u001b[0m\u001b[32m'\u001b[0m\u001b[39mcontent'\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m + \u001b[0m\u001b[32m'<|im_end|>'\u001b[0m\u001b[39m + '\u001b[0m\n",
              "\u001b[32m'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m{\u001b[0m\u001b[32m% endfor %\u001b[0m\u001b[32m}\u001b[0m\u001b[32m{\u001b[0m\u001b[32m% if add_generation_prompt %\u001b[0m\u001b[32m}\u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m '\u001b[0m\u001b[39m<|im_start|\u001b[0m\u001b[1m>\u001b[0massistant\n",
              "' \u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\u001b[1m{\u001b[0m% endif %\u001b[1m}\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "gemma_tokenizer = AutoTokenizer.from_pretrained(gemma_path)\n",
        "# print(llama_tokenizer.default_chat_template) # rich's print fails due to tag\n",
        "print(gemma_tokenizer.default_chat_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ac90ad4-ab13-4595-857b-8b982f4a6ae5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "7ac90ad4-ab13-4595-857b-8b982f4a6ae5",
        "outputId": "d161a3b1-c948-4372-cbed-766f4a5be9f6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'bos_token'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'&lt;bos&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'eos_token'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;eos&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'unk_token'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;unk&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'pad_token'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;pad&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'additional_special_tokens'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;start_of_turn&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;end_of_turn&gt;'</span><span style=\"font-weight: bold\">]</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'bos_token'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m<\u001b[0m\u001b[32mbos\u001b[0m\u001b[32m>'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m    \u001b[0m\u001b[32m'eos_token'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'<eos>'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m    \u001b[0m\u001b[32m'unk_token'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'<unk>'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m    \u001b[0m\u001b[32m'pad_token'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'<pad>'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m    \u001b[0m\u001b[32m'additional_special_tokens'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'<start_of_turn>'\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'<end_of_turn\u001b[0m\u001b[32m>\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(gemma_tokenizer.special_tokens_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jqlNlJhs68V3",
      "metadata": {
        "id": "jqlNlJhs68V3"
      },
      "outputs": [],
      "source": [
        "prompt = \"Where there is a will\"\n",
        "gemma_input = gemma_tokenizer(prompt, return_tensors='pt').to('cuda')\n",
        "# The above command needs to be reviewed for the errors it can create"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zAsmV3d87Ji4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAsmV3d87Ji4",
        "outputId": "6799963a-7347-45f6-9189-353b5204b474"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[   2, 6006, 1104,  603,  476,  877]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gemma_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35cb9f83-70a5-4103-939f-9897bc82ecbf",
      "metadata": {
        "id": "35cb9f83-70a5-4103-939f-9897bc82ecbf"
      },
      "outputs": [],
      "source": [
        "# First level of decoding customisation\n",
        "gemma_output = model.generate(\n",
        "    **gemma_input,\n",
        "    max_new_tokens=100,\n",
        "    do_sample=True,\n",
        "    # pad_token_id = llama_tokenizer.eos_token_id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "174aPl8A74WZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "174aPl8A74WZ",
        "outputId": "77542a73-0192-439f-83e3-43a6d9c18b4d"
      },
      "outputs": [],
      "source": [
        "gemma_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "937d4ebe-f79f-4459-9628-ea62468772ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "937d4ebe-f79f-4459-9628-ea62468772ea",
        "outputId": "52d09d2a-2d45-480a-961a-ff1502c4c046"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Where there is a will, there is a way.\\n\\nThis phrase expresses the concept that with a clear desire or purpose, it is possible to overcome obstacles and achieve one's goals. It reinforces the idea that hard work and persistence are essential for achieving success.\\n\\nHere are some examples of how this phrase can be used:\\n\\n- When faced with a difficult task, remind yourself that there is a will to succeed.\\n- Set SMART goals and create a plan to achieve them.\\n- If you have a dream\""
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output = gemma_tokenizer.decode(gemma_output[0],skip_special_tokens=True)\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T7rFkJ8P4vPg",
      "metadata": {
        "id": "T7rFkJ8P4vPg",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, GenerationConfig\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"my_account/my_model\")\n",
        "generation_config = GenerationConfig(\n",
        "    max_new_tokens=50, do_sample=True, top_k=50, eos_token_id=model.config.eos_token_id\n",
        ")\n",
        "generation_config.save_pretrained(\"my_account/my_model\", push_to_hub=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d04589ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "translation_generation_config = GenerationConfig(\n",
        "    num_beams=4,\n",
        "    early_stopping=True,\n",
        "    decoder_start_token_id=0,\n",
        "    eos_token_id=model.config.eos_token_id,\n",
        "    pad_token=model.config.pad_token_id,\n",
        ")\n",
        "\n",
        "# Tip: add `push_to_hub=True` to push to the Hub\n",
        "translation_generation_config.save_pretrained(\"/tmp\", \"translation_generation_config.json\")\n",
        "\n",
        "# You could then use the named generation config file to parameterize generation\n",
        "generation_config = GenerationConfig.from_pretrained(\"/tmp\", \"translation_generation_config.json\")\n",
        "inputs = tokenizer(\"translate English to French: Configuration files are easy to use!\", return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs, generation_config=generation_config)\n",
        "print(tokenizer.batch_decode(outputs, skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12200ea1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Greedy Generation\n",
        "outputs = model.generate(**inputs)\n",
        "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d688be32",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Contrastive Search\n",
        "prompt = \"Hugging Face Company is\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model.generate(**inputs, penalty_alpha=0.6, top_k=4, max_new_tokens=100)\n",
        "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc849ddb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Contrastive Search \n",
        "from transformers import set_seed\n",
        "\n",
        "set_seed(0)  # For reproducibility\n",
        "\n",
        "prompt = \"Today was an amazing day because\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model.generate(**inputs, do_sample=True, num_beams=1, max_new_tokens=100)\n",
        "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26cc1268",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Beam Search Decoding\n",
        "\n",
        "prompt = \"It is astonishing how one can\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model.generate(**inputs, num_beams=5, max_new_tokens=50)\n",
        "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26e01dc3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Beam Search Multinomial Sampling\n",
        "\n",
        "set_seed(0)  # For reproducibility\n",
        "\n",
        "prompt = \"translate English to German: The house is wonderful.\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model.generate(**inputs, num_beams=5, do_sample=True)\n",
        "tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c441e50d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Diverse beam search decoding\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "prompt = (\n",
        "    \"The Permaculture Design Principles are a set of universal design principles \"\n",
        "    \"that can be applied to any location, climate and culture, and they allow us to design \"\n",
        "    \"the most efficient and sustainable human habitation and food production systems. \"\n",
        "    \"Permaculture is a design system that encompasses a wide variety of disciplines, such \"\n",
        "    \"as ecology, landscape design, environmental science and energy conservation, and the \"\n",
        "    \"Permaculture design principles are drawn from these various disciplines. Each individual \"\n",
        "    \"design principle itself embodies a complete conceptual framework based on sound \"\n",
        "    \"scientific principles. When we bring all these separate  principles together, we can \"\n",
        "    \"create a design system that both looks at whole systems, the parts that these systems \"\n",
        "    \"consist of, and how those parts interact with each other to create a complex, dynamic, \"\n",
        "    \"living system. Each design principle serves as a tool that allows us to integrate all \"\n",
        "    \"the separate parts of a design, referred to as elements, into a functional, synergistic, \"\n",
        "    \"whole system, where the elements harmoniously interact and work together in the most \"\n",
        "    \"efficient way possible.\"\n",
        ")\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model.generate(**inputs, num_beams=5, num_beam_groups=5, max_new_tokens=30, diversity_penalty=1.0)\n",
        "\n",
        "tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a10ee7ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Speculative decoding\n",
        "prompt = \"Alice and Bob\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model.generate(**inputs, assistant_model=assistant_model)\n",
        "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a26e28d3-a303-47f3-9935-e56258002262",
      "metadata": {
        "id": "a26e28d3-a303-47f3-9935-e56258002262"
      },
      "outputs": [],
      "source": [
        "del gemma\n",
        "torch.cuda.empty_cache()  # this time the model is not offloadin\n",
        "# restarting the server to release the memory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34081f37-c363-40e6-aa75-8b5ab80a9fb2",
      "metadata": {
        "id": "34081f37-c363-40e6-aa75-8b5ab80a9fb2"
      },
      "source": [
        "### Llama observation\n",
        "\n",
        "- Llama provides the output of 10 riddles\n",
        "\n",
        "- Llama encoding and decoding is working same as roberta models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00d76358-9826-424a-97e6-f4ef06258f27",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "aa7f9689dc15421895cfb4b75e85a743"
          ]
        },
        "id": "00d76358-9826-424a-97e6-f4ef06258f27",
        "outputId": "83568689-a175-4696-a590-e7ab5c6991ee"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "code_llama_path = \"codellama/CodeLlama-7b-hf\"\n",
        "\n",
        "code_tokenizer = AutoTokenizer.from_pretrained(code_llama_path)\n",
        "\n",
        "codellama = AutoModelForCausalLM.from_pretrained(\n",
        "    code_llama_path,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=quant_config,\n",
        "    torch_dtype=torch.bfloat16\n",
        ")  # takes around 11.5GB of VRAM\n",
        "# with 4-bit quantization 5GB of VRAM is consumed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d473eea-06c7-4ade-852b-51f32e5292a0",
      "metadata": {
        "id": "1d473eea-06c7-4ade-852b-51f32e5292a0",
        "outputId": "b433cda7-357f-4b99-ecdb-52e670064ef3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% elif false == true and not '<<SYS>>' in messages[0]['content'] %}{% set loop_messages = messages %}{% set system_message = 'You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\\\n\\\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don\\\\'t know the answer to a question, please don\\\\'t share false information.' %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\\\\n' + system_message + '\\\\n<</SYS>>\\\\n\\\\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' %}{{ bos_token + '[INST] ' + content.strip() + ' [/INST]' }}{% elif message['role'] == 'system' %}{{ '<<SYS>>\\\\n' + content.strip() + '\\\\n<</SYS>>\\\\n\\\\n' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content.strip() + ' ' + eos_token }}{% endif %}{% endfor %}\""
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "code_tokenizer.default_chat_template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c4182ad-3d8b-4545-baf2-39b1d7ed1d2f",
      "metadata": {
        "id": "1c4182ad-3d8b-4545-baf2-39b1d7ed1d2f",
        "outputId": "578a0f64-977c-4cd6-f706-90f4bd2a08eb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using sep_token, but it is not set yet.\n",
            "Using pad_token, but it is not set yet.\n",
            "Using cls_token, but it is not set yet.\n",
            "Using mask_token, but it is not set yet.\n"
          ]
        }
      ],
      "source": [
        "code_input = code_tokenizer.apply_chat_template(code_message,return_tensors='pt').to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "541e2479-330a-4cfe-814f-b3703cd6a12d",
      "metadata": {
        "id": "541e2479-330a-4cfe-814f-b3703cd6a12d",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "code_output = codellama.generate(\n",
        "    code_input,\n",
        "    max_new_tokens=500,\n",
        "    do_sample=True,\n",
        "    pad_token_id=code_tokenizer.eos_token_id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09804125-3a3c-4876-b81f-7ae4ca372c5d",
      "metadata": {
        "id": "09804125-3a3c-4876-b81f-7ae4ca372c5d",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "code_output = codellama.generate(\n",
        "    code_input,\n",
        "    max_new_tokens=500,\n",
        "    do_sample=True,\n",
        "    pad_token_id=code_tokenizer.eos_token_id,\n",
        "    temperature=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4996cfd8-5120-4d7c-a69e-ed6455099d02",
      "metadata": {
        "id": "4996cfd8-5120-4d7c-a69e-ed6455099d02"
      },
      "outputs": [],
      "source": [
        "code_output = codellama.generate(\n",
        "    code_input,\n",
        "    max_new_tokens=500,\n",
        "    # do_sample=True,\n",
        "    pad_token_id=code_tokenizer.eos_token_id,\n",
        "    # temperature=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6318537-8343-4e1c-b218-25f04bd8c308",
      "metadata": {
        "id": "e6318537-8343-4e1c-b218-25f04bd8c308"
      },
      "outputs": [],
      "source": [
        "code_output = codellama.generate(\n",
        "    code_input,\n",
        "    max_new_tokens=500,\n",
        "    # do_sample=True,\n",
        "    pad_token_id=code_tokenizer.eos_token_id,\n",
        "    # temperature=0.2\n",
        "    repetition_penalty=0.5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7c754a9-97c9-4f93-9696-7da8d6a30f8e",
      "metadata": {
        "id": "e7c754a9-97c9-4f93-9696-7da8d6a30f8e"
      },
      "outputs": [],
      "source": [
        "code_output = codellama.generate(\n",
        "    code_input,\n",
        "    max_new_tokens=500,\n",
        "    do_sample=True,\n",
        "    pad_token_id=code_tokenizer.eos_token_id,\n",
        "    # temperature=0.2\n",
        "    repetition_penalty=0.5,\n",
        "    top_p=10,\n",
        "    top_k=20\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90d42456-3166-40ad-99e3-2a83cd6aa3e7",
      "metadata": {
        "collapsed": true,
        "id": "90d42456-3166-40ad-99e3-2a83cd6aa3e7",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "4bab455a-e040-4cc9-f741-7d719258577b"
      },
      "outputs": [],
      "source": [
        "output = code_output[0][len(code_input[0]):]\n",
        "code_tokenizer.decode(output, skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82a3bfce-f1ae-4230-9a76-2c0746722370",
      "metadata": {
        "id": "82a3bfce-f1ae-4230-9a76-2c0746722370"
      },
      "source": [
        "### Code Llama observation\n",
        "\n",
        "- Model inference lead to OOM with 500 tokens request, when loaded with bfloat16\n",
        "\n",
        "- Model inference worked with 500 Tokens, with quant_config done with 4-bit.\n",
        "\n",
        "- In quantisation 1GB of Vram is consumed for inference\n",
        "\n",
        "\n",
        "- **The model out was gibberish**\n",
        "\n",
        "- Requested for the code related to dictionary\n",
        "\n",
        "- Even after reviewing the generation configs, only gibberish was generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61899424-60f5-40bb-ac35-d553dcd01869",
      "metadata": {
        "id": "61899424-60f5-40bb-ac35-d553dcd01869"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "876e49f2-7b0c-4f65-b4e0-a4961036f588",
      "metadata": {
        "id": "876e49f2-7b0c-4f65-b4e0-a4961036f588"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c13522fe-47b0-4d4e-ad0e-c657161bd643",
      "metadata": {
        "id": "c13522fe-47b0-4d4e-ad0e-c657161bd643"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "925d4392-fe66-4331-9a4b-c7cc39424ee9",
      "metadata": {
        "id": "925d4392-fe66-4331-9a4b-c7cc39424ee9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "051ece87c7114977b625fecf6dc58fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1769334add064b759d44cd1033111a5f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "243f3efafa0b4c74a2b34efb4b2fb0ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dc102125cf9483bbab9fbf236ee2c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b9d3353b9f440c191e9fe2c10918cf8",
            "placeholder": "​",
            "style": "IPY_MODEL_3027ed173a1f4b6282e48eb54d6d6d55",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "3027ed173a1f4b6282e48eb54d6d6d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32ad20d4341947b4b35b78b4bf43a4a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3621c00d4d014b6d96f350b81f439833": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40b2768dcae4413b87fc3104226a0ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_1769334add064b759d44cd1033111a5f",
            "placeholder": "​",
            "style": "IPY_MODEL_9d9d8555fcf74673b4687da0e996aff4",
            "value": ""
          }
        },
        "43829a01fe2a41c490970da1eab4b57d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_89e8e0e7dc6044f0b7190e98ff4d8f2a",
            "style": "IPY_MODEL_a3b89d21ff5d4e9a86caf5cc79466116",
            "tooltip": ""
          }
        },
        "459ad13ac99d4e3ca0888767e58ebc35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a739a12768e400195b24516e2db404d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "4f23d01d0377467fbdddeecdab3cdf2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dda0f4e7855a402e9cd0c15ef97c9b6f",
              "IPY_MODEL_2dc102125cf9483bbab9fbf236ee2c7d",
              "IPY_MODEL_69f6ddd5d34541358c5caa1c2098ac85",
              "IPY_MODEL_6a7a7a83b24c4698b870fe6cdc22c588"
            ],
            "layout": "IPY_MODEL_4a739a12768e400195b24516e2db404d"
          }
        },
        "4fd12728c80e4bc5a692feacc348212c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51f6852da42b4ff4aeb1e507a91e5f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fa96886885d493b952f59f6e188376e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8f74d3de54c4696ade2588c22558499",
            "placeholder": "​",
            "style": "IPY_MODEL_beb2f40cae28480ba6232b815b51893f",
            "value": "Connecting..."
          }
        },
        "69db9bc1710149fbbd2064bcf6c0a357": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e34ab5d240024f2bae0a7efe0c639219",
            "placeholder": "​",
            "style": "IPY_MODEL_a5ef08e584c3465d908969fc492bfc94",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "69f6ddd5d34541358c5caa1c2098ac85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3621c00d4d014b6d96f350b81f439833",
            "placeholder": "​",
            "style": "IPY_MODEL_c7488ab5aec249078ec496dab7766a6f",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "6a7a7a83b24c4698b870fe6cdc22c588": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fd12728c80e4bc5a692feacc348212c",
            "placeholder": "​",
            "style": "IPY_MODEL_51f6852da42b4ff4aeb1e507a91e5f1b",
            "value": "Login successful"
          }
        },
        "89e8e0e7dc6044f0b7190e98ff4d8f2a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b9d3353b9f440c191e9fe2c10918cf8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93582d2c32944b10b78084dd8238a204": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d9d8555fcf74673b4687da0e996aff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3b89d21ff5d4e9a86caf5cc79466116": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "a5ef08e584c3465d908969fc492bfc94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "beb2f40cae28480ba6232b815b51893f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c176f814672c4c7f9d3e4e881bc3efc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_243f3efafa0b4c74a2b34efb4b2fb0ef",
            "style": "IPY_MODEL_051ece87c7114977b625fecf6dc58fef",
            "value": true
          }
        },
        "c7488ab5aec249078ec496dab7766a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8f74d3de54c4696ade2588c22558499": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce942d6a006d49ba90f373adbd39ab19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dda0f4e7855a402e9cd0c15ef97c9b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93582d2c32944b10b78084dd8238a204",
            "placeholder": "​",
            "style": "IPY_MODEL_459ad13ac99d4e3ca0888767e58ebc35",
            "value": "Token is valid (permission: write)."
          }
        },
        "e34ab5d240024f2bae0a7efe0c639219": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7d8be877e984fc4abf0f1d82b65741e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce942d6a006d49ba90f373adbd39ab19",
            "placeholder": "​",
            "style": "IPY_MODEL_32ad20d4341947b4b35b78b4bf43a4a1",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
