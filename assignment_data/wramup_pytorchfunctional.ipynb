{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook introduces the classes and function that is used in the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te1 = torch.tensor([1, 2, 3,], dtype=torch.float32)\n",
    "te1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin1 = nn.Linear(3, 1, bias=False)\n",
    "lin2 = nn.Linear(1, 1, bias=False)  # these create linear functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7392], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1 = lin1(te1)\n",
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0703], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2 = lin2(out1)\n",
    "out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.2989, -0.5447,  0.2164]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for x in lin1.parameters():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamal\\AppData\\Local\\Temp\\ipykernel_10656\\3703183840.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  s_out = F.softmax(te1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0900, 0.2447, 0.6652])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_out = F.softmax(te1)\n",
    "s_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# softmax sums to 1.0\n",
    "s_out.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is how embedding works. Small scale intro\n",
    "vocab_size = 80\n",
    "emb_dim = 6\n",
    "\n",
    "r_in = nn.Embedding(num_embeddings=vocab_size,\n",
    "                    embedding_dim=emb_dim)\n",
    "new_te1 = torch.LongTensor([12, 8, 5, 0])\n",
    "eout = r_in(new_te1)\n",
    "eout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8331,  0.4172,  1.4355,  0.0130,  2.0639,  0.6350],\n",
      "        [-1.0837, -1.9262, -1.4662,  0.1357,  0.9624,  0.7248],\n",
      "        [-0.8413,  0.6144,  1.0747, -0.8504, -0.4385, -0.8482],\n",
      "        [-1.1507, -0.0981, -0.5113,  0.7938,  0.9766, -1.2716]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(eout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19, 12, 10],\n",
      "        [32, 21, 16],\n",
      "        [45, 30, 22],\n",
      "        [58, 39, 28]])\n"
     ]
    }
   ],
   "source": [
    "# detour to matrix multiplication\n",
    "\n",
    "a = torch.tensor([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "b = torch.tensor([[7, 6, 2], [6, 3, 4]])\n",
    "\n",
    "print(a @ b)  # @ is short for matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3 8\n",
      "torch.Size([6, 8])\n"
     ]
    }
   ],
   "source": [
    "# detour to playing with shapes with vieow\n",
    "\n",
    "input = torch.rand((2, 3, 8))\n",
    "\n",
    "n, r, c = input.shape\n",
    "print(n, r, c)\n",
    "output = input.view(n * r, c) \n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue further experiment with view\n",
    "\n",
    "b = torch.randint(1, 75, size=(2, 8))\n",
    "d = torch.randint(1, 75, size=(2, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamal\\AppData\\Local\\Temp\\ipykernel_10656\\867071612.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  b = torch.tensor(torch.randint(1, 75, size=(2, 8)), dtype=torch.float32)\n",
      "C:\\Users\\kamal\\AppData\\Local\\Temp\\ipykernel_10656\\867071612.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  d = torch.tensor(torch.randint(1, 75, size=(2, 8)), dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# playing with type casting, following will throw error \n",
    "\n",
    "b = torch.tensor(torch.randint(1, 75, size=(2, 8)), dtype=torch.float32)\n",
    "d = torch.tensor(torch.randint(1, 75, size=(2, 8)), dtype=torch.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor type casting\n",
    "bf = b.float() \n",
    "bf.dtype\n",
    "df = d.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([55.,  2., 58., 70., 28., 10., 58., 56., 40., 55., 44., 18., 37., 48.,\n",
       "        63., 27.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.view(2 * 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20662.5156)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-entropy \n",
    "ce = F.cross_entropy(bf.view(16), df.view(16))\n",
    "ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "wineds = datasets.load_wine()\n",
    "data = wineds['data']\n",
    "data.shape\n",
    "tgt = wineds['target']\n",
    "tgt.shape\n",
    "# take a look at the data, and try to access parts of it using indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before diving into creating Torch datasets, dive into Numpy to Tensor conversion\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.linspace(50, 686, 250)\n",
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Moving from numpy to tensor using from_numpy\n",
    "\n",
    "x_tensor = torch.from_numpy(x_data.astype(np.float32))\n",
    "x_tensor.shape\n",
    "x_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a loader class by inheriting the Dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x = torch.from_numpy(x_data.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y_data.astype(np.float32))\n",
    "        self.n_samples = x_data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_ds = WineDataset(x_data=data,\n",
    "                      y_data=tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.3160e+01, 2.3600e+00, 2.6700e+00, 1.8600e+01, 1.0100e+02, 2.8000e+00,\n",
       "         3.2400e+00, 3.0000e-01, 2.8100e+00, 5.6800e+00, 1.0300e+00, 3.1700e+00,\n",
       "         1.1850e+03]),\n",
       " tensor(0.))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_ds[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader can accept the Dataset object\n",
    "\n",
    "wine_dl = DataLoader(wine_ds, shuffle=True, batch_size=3)\n",
    "dloader_iter = iter(wine_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1.3900e+01, 1.6800e+00, 2.1200e+00, 1.6000e+01, 1.0100e+02, 3.1000e+00,\n",
       "          3.3900e+00, 2.1000e-01, 2.1400e+00, 6.1000e+00, 9.1000e-01, 3.3300e+00,\n",
       "          9.8500e+02],\n",
       "         [1.3030e+01, 9.0000e-01, 1.7100e+00, 1.6000e+01, 8.6000e+01, 1.9500e+00,\n",
       "          2.0300e+00, 2.4000e-01, 1.4600e+00, 4.6000e+00, 1.1900e+00, 2.4800e+00,\n",
       "          3.9200e+02],\n",
       "         [1.3450e+01, 3.7000e+00, 2.6000e+00, 2.3000e+01, 1.1100e+02, 1.7000e+00,\n",
       "          9.2000e-01, 4.3000e-01, 1.4600e+00, 1.0680e+01, 8.5000e-01, 1.5600e+00,\n",
       "          6.9500e+02]]),\n",
       " tensor([0., 1., 2.])]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(dloader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to learn the Pytorch Semantics, (not syntax)\n",
    "\n",
    "# Each tensor has at least one dimension.\n",
    "# When iterating over the dimension sizes, start at \n",
    "# the trailing dimension, the dimension sizes must \n",
    "# either be equal, one of them is 1, or one of them\n",
    "# does not exist.\n",
    "\n",
    "x = torch.empty(5, 7, 8)\n",
    "y = torch.empty(5, 7, 8)\n",
    "# tensor of same shapes are broadcastable\n",
    "\n",
    "x = torch.empty((0, ))\n",
    "x = torch.empty(2, 2)\n",
    "# cannot broadcast as one of the dimension is not 1\n",
    "\n",
    "a = torch.rand((3, 3, 1))\n",
    "b = torch.rand((3, 1))\n",
    "\n",
    "# 1st trailing dimension: both have size 1\n",
    "# 2nd trailing dimension: a size == b size\n",
    "# 3rd trailing dimension: b dimension doesn't exist \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When it comes to Matrix Multiplication, there are following pairs one has to identify\n",
    "# vector * vector, matrix * vector, batched mat * vector(bc) \n",
    "# batched matrix * batched matrix, batched matrix * broadcasted matrix\n",
    "# A vector is of shape 1 row n col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.4056)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector X vector is acceptable, and return dot product\n",
    "tensor2 = torch.rand(3)  # Size([3]) \n",
    "\n",
    "tensor1 = torch.tensor([5, 6, 8], dtype=torch.float32)  # Size([3])\n",
    "\n",
    "tensor1 @ tensor2  # returns dot-pdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.0336,  6.4768, 12.4093])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matensor = torch.tensor([[1, 3, 4,],\n",
    "                         [5, 7, 6,],\n",
    "                         [9, 2, 8]],\n",
    "                         dtype=torch.float32)\n",
    "\n",
    "tensor2 @ matensor  # 1D to 2D is processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8100, 0.9030, 0.4469],\n",
       "        [1.0553, 1.0003, 1.0467],\n",
       "        [1.1010, 0.9913, 1.0810]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor5 = torch.rand(3, 3, 4)\n",
    "tensor6 = torch.rand(4)\n",
    "\n",
    "tensor5 @ tensor6 # batched tensor broadcasts over vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 3])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor7 = torch.rand(4, 3, 3)\n",
    "\n",
    "tensor8 = torch.rand(4, 3, 3)\n",
    "\n",
    "(tensor7 @ tensor8).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 9])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returning to work on the Network Layers\n",
    "\n",
    "flaten = nn.Flatten(start_dim=1, end_dim=-1)\n",
    "print(tensor8.shape)\n",
    "x = flaten(tensor8)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([36])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returning to work on the Network Layers\n",
    "\n",
    "flaten = nn.Flatten(start_dim=0, end_dim=-1)\n",
    "print(tensor8.shape)\n",
    "x = flaten(tensor8)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 3])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returning to work on the Network Layers\n",
    "\n",
    "flaten = nn.Flatten(start_dim=0, end_dim=-2)\n",
    "print(tensor8.shape)\n",
    "x = flaten(tensor8)\n",
    "x.shape\n",
    "\n",
    "# the pattern tested with various dimensions of tensors\n",
    "# the intuition point is the start-dim that tells from which \n",
    "# dimension tensor has to be flattened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 784])\n"
     ]
    }
   ],
   "source": [
    "flaten = nn.Flatten(start_dim=1, end_dim=-1)\n",
    "# -1 means the final value is calculated by torch\n",
    "test_data2 = torch.rand(5, 28, 28)\n",
    "test_out = flaten(test_data2)  # Size([5, 784])\n",
    "\n",
    "print(test_out.shape)  # Size([5, 784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = nn.Linear(784, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1134, -0.7086],\n",
       "        [-0.2925, -0.5162],\n",
       "        [-0.3797, -0.6359],\n",
       "        [-0.3133, -0.6307],\n",
       "        [-0.0352, -0.6771]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1(test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1134, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0000, 0.0000]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = nn.ReLU()\n",
    "hi2 = r1(l1(test_out))\n",
    "hi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sequential\n",
    "\n",
    "seq2 = nn.Sequential(\n",
    "    flaten,\n",
    "    nn.Linear(784, 512),\n",
    "    r1,\n",
    "    nn.Linear(512, 512),\n",
    "    r1,\n",
    "    nn.Linear(512, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0083, -0.0336,  0.0222,  0.0419, -0.0087, -0.0420,  0.0052,  0.0352,\n",
       "         -0.0825,  0.0571],\n",
       "        [-0.0334, -0.0558,  0.0160,  0.0594, -0.0261, -0.0602, -0.0141,  0.0507,\n",
       "         -0.0760,  0.0447],\n",
       "        [-0.0319, -0.0464,  0.0377,  0.0456, -0.0057, -0.0249, -0.0117,  0.0662,\n",
       "         -0.0425,  0.0201],\n",
       "        [ 0.0109, -0.0131,  0.0319, -0.0034, -0.0013, -0.0178, -0.0502,  0.0193,\n",
       "         -0.0444,  0.0038],\n",
       "        [-0.0253, -0.0313, -0.0276,  0.0212, -0.0137, -0.0233,  0.0532,  0.0746,\n",
       "         -0.1118,  0.0811]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(seq2(test_out).shape)\n",
    "seq2(test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 1.weight | size: torch.Size([512, 784]) | vals : tensor([[ 0.0016, -0.0325,  0.0260,  ...,  0.0055,  0.0083, -0.0276],\n",
      "        [-0.0063,  0.0069,  0.0278,  ..., -0.0162, -0.0172,  0.0195]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Layer: 1.bias | size: torch.Size([512]) | vals : tensor([-0.0241, -0.0257], grad_fn=<SliceBackward0>)\n",
      "Layer: 3.weight | size: torch.Size([512, 512]) | vals : tensor([[-0.0212, -0.0266,  0.0416,  ..., -0.0034, -0.0057,  0.0126],\n",
      "        [-0.0159,  0.0261, -0.0367,  ..., -0.0029, -0.0320, -0.0329]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Layer: 3.bias | size: torch.Size([512]) | vals : tensor([0.0085, 0.0295], grad_fn=<SliceBackward0>)\n",
      "Layer: 5.weight | size: torch.Size([10, 512]) | vals : tensor([[ 0.0103, -0.0404, -0.0303,  ..., -0.0007,  0.0362, -0.0076],\n",
      "        [-0.0039, -0.0085,  0.0257,  ..., -0.0183, -0.0011,  0.0262]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Layer: 5.bias | size: torch.Size([10]) | vals : tensor([ 0.0062, -0.0389], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for name, params in seq2.named_parameters():\n",
    "    print(f'Layer: {name} | size: {params.size()} | vals : {params[:2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3232, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "The z grad fn: <AddBackward0 object at 0x0000027BB93AF670>\n",
      "The loss grad fn: <BinaryCrossEntropyWithLogitsBackward0 object at 0x0000027BB93AF5B0>\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Basic model (need to practice)\n",
    "x = torch.ones(5)\n",
    "y = torch.zeros(3)\n",
    "\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "\n",
    "z = torch.matmul(x, w) + b\n",
    "\n",
    "loss = F.binary_cross_entropy_with_logits(z, y)\n",
    "print(loss)\n",
    "\n",
    "print(f\"The z grad fn: {z.grad_fn}\")\n",
    "print(f\"The loss grad fn: {loss.grad_fn}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    a = torch.matmul(x, w) + b\n",
    "print(z.requires_grad)  # returns False\n",
    "\n",
    "f = torch.matmul(x, w) + b\n",
    "f_det = f.detach()\n",
    "print(f_det.requires_grad)  # returns false\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tform",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
