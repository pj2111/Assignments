{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pj2111/Assignments/blob/master/assignment_data/warmup_pytorch_modeldesign_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x9UxCc3sZpah"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torch datasets > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs3AjFlnjU4p"
      },
      "source": [
        "# 1) Design the model (input, output size and forward pass)\n",
        "    # Input, target data must have shape of m x n, i.e both must have features\n",
        "    # Model needs to designed by keeping the feature length in mind, as these will be processed\n",
        "# 2) construct loss and optimizer\n",
        "    # torch.nn module contains the variety of Loss Criterions\n",
        "    # torch.optim module contains various optimizers\n",
        "# 3) training loop\n",
        "\n",
        "###  - forward pass: compute prediction\n",
        "    # loss criterion is called with the target and predicted values\n",
        "\n",
        "###  - backward pass: compute gradient & update weights\n",
        "    # optimizers will take care of gradient, weight updates of the model\n",
        "    # remember to pass optimizer.zero_grad() for the gradient to be\n",
        "    # reset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuP5I56hjhbl"
      },
      "source": [
        "### Start by working on bare-bones matrix model LinReg Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EEKbbZYWcVQ8"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZkZdottLcgsk"
      },
      "outputs": [],
      "source": [
        "X = torch.tensor([1, 2, 3, 4, 5, 6], dtype=torch.float32)\n",
        "y = torch.tensor([5, 8, 11, 14, 17, 20], dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 5.,  8., 11., 14., 17., 20.])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "cXFtOl1Ziqe8"
      },
      "outputs": [],
      "source": [
        "# here is the weights of the model, simple one-c tensor with gradient calc ability\n",
        "\n",
        "w = torch.tensor(0.0, requires_grad=True, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 5.,  8., 11., 14., 17., 20.])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VqI8p0qTc6Om"
      },
      "outputs": [],
      "source": [
        "def forward(x):\n",
        "  return x * w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "n0T_QyLucVUu"
      },
      "outputs": [],
      "source": [
        "def loss(y, y_pred):\n",
        "  return ((y_pred - y) ** 2).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5Wt_c6n3cVYw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Gradient calculation is done using Numpy\n",
        "def gradient(x, y, y_pred):\n",
        "  return np.dot(2 * x, y_pred - y).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVKr0UYNcVcS",
        "outputId": "f4e8230c-9534-486c-a559-c37c2131bb19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predict with simple forward fn: 0.0\n"
          ]
        }
      ],
      "source": [
        "# Try predict what is the output before model training\n",
        "\n",
        "print(f\"Predict with simple forward fn: {forward(5)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rjgEQSgzcVf2"
      },
      "outputs": [],
      "source": [
        "# beginning the training process\n",
        "\n",
        "learning_rate = 0.01\n",
        "n_iters = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XzVF8Le1cVjm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1: w=  6.300000 loss:  182.500000 dw : -630.000000\n",
            "epoch 2: w=  1.134000 loss:  122.965034 dw :  516.600037\n",
            "epoch 3: w=  5.370121 loss:  82.933693 dw : -423.612091\n",
            "epoch 4: w=  1.896501 loss:  56.016628 dw :  347.361908\n",
            "epoch 5: w=  4.744869 loss:  37.917572 dw : -284.836761\n",
            "epoch 6: w=  2.409207 loss:  25.747789 dw :  233.566193\n",
            "epoch 7: w=  4.324450 loss:  17.564817 dw : -191.524307\n",
            "epoch 8: w=  2.753951 loss:  12.062580 dw :  157.049911\n",
            "epoch 9: w=  4.041760 loss:  8.362876 dw : -128.780899\n",
            "epoch 10: w=  2.985757 loss:  5.875196 dw :  105.600327\n",
            "epoch 11: w=  3.851679 loss:  4.202481 dw : -86.592247\n",
            "epoch 12: w=  3.141623 loss:  3.077748 dw :  71.005646\n",
            "epoch 13: w=  3.723869 loss:  2.321479 dw : -58.224648\n",
            "epoch 14: w=  3.246427 loss:  1.812963 dw :  47.744217\n",
            "epoch 15: w=  3.637930 loss:  1.471037 dw : -39.150284\n",
            "epoch 16: w=  3.316898 loss:  1.241126 dw :  32.103245\n",
            "epoch 17: w=  3.580144 loss:  1.086532 dw : -26.324627\n",
            "epoch 18: w=  3.364282 loss:  0.982584 dw :  21.586185\n",
            "epoch 19: w=  3.541289 loss:  0.912690 dw : -17.700691\n",
            "epoch 20: w=  3.396143 loss:  0.865693 dw :  14.514581\n",
            "epoch 21: w=  3.515163 loss:  0.834092 dw : -11.901981\n",
            "epoch 22: w=  3.417566 loss:  0.812844 dw :  9.759646\n",
            "epoch 23: w=  3.497596 loss:  0.798556 dw : -8.002934\n",
            "epoch 24: w=  3.431971 loss:  0.788950 dw :  6.562443\n",
            "epoch 25: w=  3.485784 loss:  0.782490 dw : -5.381226\n",
            "epoch 26: w=  3.441658 loss:  0.778146 dw :  4.412601\n",
            "epoch 27: w=  3.477841 loss:  0.775225 dw : -3.618337\n",
            "epoch 28: w=  3.448170 loss:  0.773262 dw :  2.967053\n",
            "epoch 29: w=  3.472500 loss:  0.771941 dw : -2.432988\n",
            "epoch 30: w=  3.452550 loss:  0.771053 dw :  1.995069\n"
          ]
        }
      ],
      "source": [
        "# gradients calculated using numpy method\n",
        "w = 0.0\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  y_pred = forward(X)\n",
        "  l = loss(y , y_pred)\n",
        "  dw = gradient(X, y, y_pred)\n",
        "  w -= learning_rate * dw\n",
        "  if epoch % 1 == 0:\n",
        "    print(f\"epoch {epoch + 1}: w= {w: 3f} loss: {l: 8f} dw : {dw: 3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZAaGzzhcVnS",
        "outputId": "1f853467-d322-4ec9-c8e2-68ce3006d545"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction after training f(5) = 17.26274795532227\n"
          ]
        }
      ],
      "source": [
        "print(f\"Prediction after training f(5) = {forward(5)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 3.4525,  6.9051, 10.3576, 13.8102, 17.2627, 20.7153])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# [5, 8, 11, 14, 17, 20]\n",
        "# for i in X:\n",
        "    # print(forward(i))\n",
        "    \n",
        "X*w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "iIQqoYZFilHP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1: w=  1.050000 loss:  182.500000\n",
            "epoch 2: w=  1.781500 loss:  88.971252\n",
            "epoch 3: w=  2.291111 loss:  43.577595\n",
            "epoch 4: w=  2.646141 loss:  21.546038\n",
            "epoch 5: w=  2.893478 loss:  10.853137\n",
            "epoch 6: w=  3.065790 loss:  5.663396\n",
            "epoch 7: w=  3.185834 loss:  3.144587\n",
            "epoch 8: w=  3.269464 loss:  1.922097\n",
            "epoch 9: w=  3.327727 loss:  1.328767\n",
            "epoch 10: w=  3.368316 loss:  1.040798\n",
            "epoch 11: w=  3.396594 loss:  0.901035\n",
            "epoch 12: w=  3.416294 loss:  0.833201\n",
            "epoch 13: w=  3.430018 loss:  0.800278\n",
            "epoch 14: w=  3.439579 loss:  0.784300\n",
            "epoch 15: w=  3.446240 loss:  0.776544\n",
            "epoch 16: w=  3.450881 loss:  0.772780\n",
            "epoch 17: w=  3.454114 loss:  0.770953\n",
            "epoch 18: w=  3.456366 loss:  0.770067\n",
            "epoch 19: w=  3.457935 loss:  0.769637\n",
            "epoch 20: w=  3.459028 loss:  0.769428\n",
            "epoch 21: w=  3.459790 loss:  0.769326\n",
            "epoch 22: w=  3.460320 loss:  0.769277\n",
            "epoch 23: w=  3.460690 loss:  0.769253\n",
            "epoch 24: w=  3.460947 loss:  0.769242\n",
            "epoch 25: w=  3.461126 loss:  0.769236\n",
            "epoch 26: w=  3.461251 loss:  0.769233\n",
            "epoch 27: w=  3.461338 loss:  0.769232\n",
            "epoch 28: w=  3.461399 loss:  0.769232\n",
            "epoch 29: w=  3.461441 loss:  0.769231\n",
            "epoch 30: w=  3.461471 loss:  0.769231\n"
          ]
        }
      ],
      "source": [
        "# gradients calculated using tensor backward() method\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  y_pred = forward(X)\n",
        "  l = loss(y , y_pred)\n",
        "  l.backward()  # this part is done by pytorch\n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate * w.grad\n",
        "  w.grad.zero_()\n",
        "  if epoch % 1 == 0:\n",
        "    print(f\"epoch {epoch + 1}: w= {w: 3f} loss: {l: 8f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BupQuCjDjwfu"
      },
      "source": [
        "#### Going full torch mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "X5Npa5mGkDWF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SLpCHOUucVqn"
      },
      "outputs": [],
      "source": [
        "# the shape of the input is different, when used with torch models\n",
        "X = torch.tensor([[1], [2], [3], [4], [5]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8], [10]], dtype=torch.float32)\n",
        "\n",
        "# n_features is the cols persent in each datapoint, both inputs & targets\n",
        "n_samples, n_features = X.shape\n",
        "x_test = torch.tensor([5],\n",
        "                      dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "LCCDLfHvcVt3"
      },
      "outputs": [],
      "source": [
        "# Models are basic python classes with the blueprint.\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LinearRegression, self).__init__()\n",
        "        # define layers\n",
        "        self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lin(x)\n",
        "\n",
        "model = LinearRegression(n_features, n_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPi86oy8cVxT",
        "outputId": "4b70786d-0938-41c1-84db-0566eb2e5c32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prediction before training: f(5)= 4.796\n"
          ]
        }
      ],
      "source": [
        "loss = nn.MSELoss()\n",
        "optim = torch.optim.SGD(model.parameters(),\n",
        "                        lr=0.01)\n",
        "\n",
        "print(f\"prediction before training: f(5)= {model(x_test).item():.3f}\")\n",
        "# training\n",
        "learning_rate = 0.01\n",
        "n_iters = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[1.8262]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.6263], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for i in model.parameters():\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "mm2zEoO1luaI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1: w = 1.094, loss: 11.23808289\n",
            "epoch 2: w = 1.264, loss: 6.58492279\n",
            "epoch 3: w = 1.394, loss: 3.87304926\n",
            "epoch 4: w = 1.493, loss: 2.29246354\n",
            "epoch 5: w = 1.569, loss: 1.37113631\n",
            "epoch 6: w = 1.627, loss: 0.83399516\n",
            "epoch 7: w = 1.671, loss: 0.52073926\n",
            "epoch 8: w = 1.705, loss: 0.33795559\n",
            "epoch 9: w = 1.731, loss: 0.23120518\n",
            "epoch 10: w = 1.751, loss: 0.16876490\n",
            "epoch 11: w = 1.767, loss: 0.13214798\n",
            "epoch 12: w = 1.779, loss: 0.11058128\n",
            "epoch 13: w = 1.788, loss: 0.09778684\n",
            "epoch 14: w = 1.795, loss: 0.09010570\n",
            "epoch 15: w = 1.801, loss: 0.08540602\n",
            "epoch 16: w = 1.806, loss: 0.08244508\n",
            "epoch 17: w = 1.809, loss: 0.08049901\n",
            "epoch 18: w = 1.812, loss: 0.07914598\n",
            "epoch 19: w = 1.814, loss: 0.07813971\n",
            "epoch 20: w = 1.816, loss: 0.07733725\n",
            "epoch 21: w = 1.818, loss: 0.07665491\n",
            "epoch 22: w = 1.819, loss: 0.07604417\n",
            "epoch 23: w = 1.820, loss: 0.07547637\n",
            "epoch 24: w = 1.821, loss: 0.07493521\n",
            "epoch 25: w = 1.822, loss: 0.07441089\n",
            "epoch 26: w = 1.823, loss: 0.07389782\n",
            "epoch 27: w = 1.824, loss: 0.07339267\n",
            "epoch 28: w = 1.825, loss: 0.07289355\n",
            "epoch 29: w = 1.826, loss: 0.07239939\n",
            "epoch 30: w = 1.826, loss: 0.07190935\n"
          ]
        }
      ],
      "source": [
        "# Looking at the LinReg Model Training\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # prediction to be extracted\n",
        "    y_pred = model(X)\n",
        "    # compute loss\n",
        "    l = loss(Y, y_pred)\n",
        "    # get gradient ==> backward()\n",
        "    l.backward()  # will calculate the grad w.r.t 'w'\n",
        "    # update weights is done by the optimizert\n",
        "    # with torch.no_grad():\n",
        "    #    w -= learning_rate * w.grad\n",
        "    optim.step()\n",
        "    # make the accumulated grad to 0\n",
        "    optim.zero_grad()\n",
        "    # printing epoch\n",
        "    if epoch % 1 == 0:\n",
        "        [w, b] = model.parameters()\n",
        "        # observe how the weights are extracted to display\n",
        "        print(f\"epoch {epoch + 1}: w = {w[0][0].item():.3f}, loss: {l:.8f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixiswewcluXs",
        "outputId": "92c26ab8-c2ef-420c-8059-8c4180956b64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prediction after training: f(5)= 9.757\n"
          ]
        }
      ],
      "source": [
        "print(f\"prediction after training: f(5)= {model(x_test).item():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_kKJZrNqkUE"
      },
      "source": [
        "### Fine Tuning model from Scratch with Mnist Data\n",
        "\n",
        "This part of the notebook is self-contained, and can be extracted into a script for execution\n",
        "\n",
        "- MNIST data loader\n",
        "\n",
        "- Dataload and transformation\n",
        "\n",
        "- Design Multi-layer neural net with activation function\n",
        "\n",
        "- Loss and Optimiser declaration\n",
        "\n",
        "- Training loop with batches\n",
        "\n",
        "- model evaluation using accuracy\n",
        "\n",
        "- enable GPU support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vncrIC-kqf98"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pYJfluBTrRDT"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "z_11l0lsqf60"
      },
      "outputs": [],
      "source": [
        "# preliminary data\n",
        "input_size = 784\n",
        "hidden_size = 100\n",
        "\n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5oljH_4qf4N",
        "outputId": "463b0b17-ed1e-438b-e09b-8638b351969f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<PIL.Image.Image image mode=L size=28x28>, 5)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_train = torchvision.datasets.MNIST(root='./data', train=True, download=False)\n",
        "raw_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "em5VK9r5uZYO",
        "outputId": "5fef3f3e-2c56-4c89-966b-80b85daa146c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA5klEQVR4nGNgoD9gRGJr+aSevsAw4Rc2demf/v379++fE1ZDhF78+/fv3793blhlM778e/Dv379e7A44/+/Sv3//lLBLhpz79+/fP00cbpe4+O/fv9VwLguyXLSeDgMDw1Fs2jSu/fr3D8VOJoSkpiLEmAKsNuZ9+/cPp52TbgswsEzmw+FYBgYGxoZ/t+VxSbL/+3dNBpdk179/JehiwhujGBgYGBgkP2AJviX/rturMBhHnvv3r5sDXdLy6L9/97Z8/Pfv71VuTLt6Mv/9+/fv3783yIIwf5aw8zAYRDJ8xB7TdAQABFdhZWAfWxoAAAAASUVORK5CYII=",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "raw_train[10][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLC9rkYEqf12"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "imshow(raw_train[0][0]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "83vqF4R_qfzd"
      },
      "outputs": [],
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                           transform=transforms.ToTensor())\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size,\n",
        "                          shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size,\n",
        "                         shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPpEGqB3qfuy",
        "outputId": "4ae03c33-69da-40af-9607-13a8f2395027"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
          ]
        }
      ],
      "source": [
        "# usage of iterator / generator\n",
        "examples = iter(train_loader)\n",
        "\n",
        "samples, labels = next(examples)\n",
        "\n",
        "print(samples.shape, labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "Owe9EeVVvGyO",
        "outputId": "099c00d3-190e-4409-8515-5866d2d7778b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 8 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for i in range(8):\n",
        "    plt.subplot(2, 4, i+1)\n",
        "    plt.imshow(samples[i][0], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "yBeMaHHQqfsP"
      },
      "outputs": [],
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "5A0uTjWMluQ9"
      },
      "outputs": [],
      "source": [
        "model = NeuralNet(input_size=input_size,\n",
        "                  hidden_size=hidden_size,\n",
        "                  num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "w4L7usIFvRfm"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "qBCGz2sKvRdU"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "\n",
        "running_loss = 0.0\n",
        "\n",
        "running_corrects = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JHdwuQLvRbI"
      },
      "outputs": [],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"entering epoch: {epoch + 1}\\n\")\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # 100, 1, 28, 28\n",
        "        # 100, 784\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "    # forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "    # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        running_corrects += (predicted == labels).sum().item()\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(f\"epoch: {epoch+1} / {num_epochs}, step {i + 1} / {n_total_steps} loss= {loss.item():.3f}\")\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4oCCymOvRVB"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples =0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1,28*28)\n",
        "        outputs = model(images)\n",
        "        # value, index\n",
        "        _, predictions = torch.max(outputs,1)\n",
        "        n_samples += labels.shape[0]\n",
        "        n_correct = (predictions == labels).sum().item()\n",
        "\n",
        "    acc = 100 * n_correct / n_samples\n",
        "    print(f\"accuracy = {acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_k8gbF6vRST"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pnFTPaTvRPd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3kVDk2ovRMJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPiwyTl/GQPKXZrvimvgjc7",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
