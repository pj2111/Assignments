{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Individual tokens inside the sentences are classified into different types.\n",
    "default_model = \"dbmdz/bert-large-cased-finetuned-conll03-english\"  # 1.4GB model\n",
    "# classifier = pipeline(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tokenizer = AutoTokenizer.from_pretrained(default_model,\n",
    "                                              resume_download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O means the word doesn’t correspond to any entity.\n",
    "\n",
    "B-PER/I-PER means the word corresponds to the beginning of/is inside a person entity.\n",
    "\n",
    "B-ORG/I-ORG means the word corresponds to the beginning of/is inside an organization entity.\n",
    "\n",
    "B-LOC/I-LOC means the word corresponds to the beginning of/is inside a location entity.\n",
    "\n",
    "B-MISC/I-MISC means the word corresponds to the beginning of/is inside a miscellaneous entity.\n",
    "\n",
    "O, Outside of a named entity\n",
    "\n",
    "B-MIS, Beginning of a miscellaneous entity right after another miscellaneous entity\n",
    "\n",
    "I-MIS, Miscellaneous entity\n",
    "\n",
    "B-PER, Beginning of a person’s name right after another person’s name\n",
    "\n",
    "I-PER, Person’s name\n",
    "\n",
    "B-ORG, Beginning of an organisation right after another organisation\n",
    "\n",
    "I-ORG, Organisation\n",
    "\n",
    "B-LOC, Beginning of a location right after another location\n",
    "\n",
    "I-LOC, Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "ner_model = AutoModelForTokenClassification.from_pretrained(default_model,\n",
    "                                                            resume_download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"dbmdz/bert-large-cased-finetuned-conll03-english\",\n",
       "  \"_num_labels\": 9,\n",
       "  \"architectures\": [\n",
       "    \"BertForTokenClassification\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 1024,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"O\",\n",
       "    \"1\": \"B-MISC\",\n",
       "    \"2\": \"I-MISC\",\n",
       "    \"3\": \"B-PER\",\n",
       "    \"4\": \"I-PER\",\n",
       "    \"5\": \"B-ORG\",\n",
       "    \"6\": \"I-ORG\",\n",
       "    \"7\": \"B-LOC\",\n",
       "    \"8\": \"I-LOC\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 4096,\n",
       "  \"label2id\": {\n",
       "    \"B-LOC\": 7,\n",
       "    \"B-MISC\": 1,\n",
       "    \"B-ORG\": 5,\n",
       "    \"B-PER\": 3,\n",
       "    \"I-LOC\": 8,\n",
       "    \"I-MISC\": 2,\n",
       "    \"I-ORG\": 6,\n",
       "    \"I-PER\": 4,\n",
       "    \"O\": 0\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 16,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.39.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 28996\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ner_model.config\n",
    "\n",
    "from transformers import AutoConfig\n",
    "AutoConfig.from_pretrained(default_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\n",
    "\"O\",       # Outside of a named entity\n",
    "\"B-MISC\",  # Beginning of a miscellaneous entity right after another miscellaneous entity\n",
    "\"I-MISC\",  # Miscellaneous entity\n",
    "\"B-PER\",   # Beginning of a person's name right after another person's name\n",
    "\"I-PER\",   # Person's name\n",
    "\"B-ORG\",   # Beginning of an organisation right after another organisation\n",
    "\"I-ORG\",   # Organisation\n",
    "\"B-LOC\",   # Beginning of a location right after another location\n",
    "\"I-LOC\"    # Location \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I am from United States and I like playing with data Ramesh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'am',\n",
       " 'from',\n",
       " 'United',\n",
       " 'States',\n",
       " 'and',\n",
       " 'I',\n",
       " 'like',\n",
       " 'playing',\n",
       " 'with',\n",
       " 'data',\n",
       " 'Ram',\n",
       " '##esh']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_tokenized = ner_tokenizer.tokenize(sentence)\n",
    "sentence_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,   146,  1821,  1121,  1244,  1311,  1105,   146,  1176,  1773,\n",
       "          1114,  2233, 11447, 10654,   102]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_input = ner_tokenizer.encode(sentence, return_tensors='pt')\n",
    "sentence_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0070e+01, -2.1285e+00, -1.5390e+00, -2.0444e+00, -1.5033e+00,\n",
       "          -1.8817e+00, -1.0944e+00, -1.9918e+00,  5.8473e-01],\n",
       "         [ 1.0482e+01, -2.5018e+00, -1.7410e+00, -2.6160e+00, -6.1306e-02,\n",
       "          -2.0731e+00,  3.4023e-01, -2.1875e+00, -5.3043e-01],\n",
       "         [ 1.1118e+01, -2.3193e+00, -1.7046e+00, -2.4368e+00, -6.8214e-01,\n",
       "          -1.8959e+00,  1.4921e-01, -1.8533e+00, -5.1833e-01],\n",
       "         [ 1.0280e+01, -2.5857e+00, -1.0144e+00, -2.3723e+00, -1.0276e+00,\n",
       "          -1.7403e+00, -2.1357e-03, -2.1665e+00,  3.0278e-01],\n",
       "         [-4.8959e-01, -2.0961e+00, -6.2558e-01, -2.2961e+00, -1.3618e+00,\n",
       "          -2.0690e+00, -1.0093e+00, -1.3048e+00,  8.8662e+00],\n",
       "         [-1.4161e+00, -1.8178e+00, -5.6483e-01, -2.2271e+00, -1.4522e+00,\n",
       "          -2.2266e+00, -1.2002e+00, -1.2413e+00,  8.7637e+00],\n",
       "         [ 1.1036e+01, -2.4121e+00, -1.5921e+00, -2.4863e+00, -1.3190e+00,\n",
       "          -1.5500e+00,  6.4275e-03, -1.7939e+00, -3.4909e-01],\n",
       "         [ 1.1186e+01, -2.3898e+00, -1.5176e+00, -2.5681e+00, -7.8249e-01,\n",
       "          -1.8102e+00, -1.7170e-01, -1.9194e+00, -7.1405e-01],\n",
       "         [ 1.1479e+01, -2.3559e+00, -1.2051e+00, -2.6351e+00, -1.0897e+00,\n",
       "          -1.8197e+00, -2.3955e-01, -1.8723e+00, -7.9155e-01],\n",
       "         [ 1.1569e+01, -2.4212e+00, -9.2269e-01, -2.7095e+00, -1.3123e+00,\n",
       "          -1.9065e+00, -1.5261e-01, -1.8674e+00, -9.2102e-01],\n",
       "         [ 1.1516e+01, -2.3888e+00, -8.6533e-01, -2.6910e+00, -1.2451e+00,\n",
       "          -1.9952e+00, -3.7431e-01, -1.8713e+00, -9.3357e-01],\n",
       "         [ 1.1226e+01, -2.3456e+00, -7.4065e-01, -2.8541e+00, -1.0089e+00,\n",
       "          -1.9645e+00,  4.5646e-02, -1.8419e+00, -9.9125e-01],\n",
       "         [ 1.6967e-01, -2.0559e+00, -7.4033e-01, -2.7475e+00,  6.3590e+00,\n",
       "          -2.4282e+00,  1.2192e-01, -2.7365e+00,  4.8693e-01],\n",
       "         [ 1.2625e+00, -1.8687e+00,  4.6671e-02, -3.6221e+00,  4.0317e+00,\n",
       "          -2.2456e+00,  1.1748e+00, -2.9106e+00,  1.3734e-01],\n",
       "         [ 1.0070e+01, -2.1285e+00, -1.5390e+00, -2.0444e+00, -1.5033e+00,\n",
       "          -1.8817e+00, -1.0944e+00, -1.9918e+00,  5.8473e-01]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = ner_model(sentence_input)[0]\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 8, 8, 0, 0, 0, 0, 0, 0, 4, 4, 0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "predictions = torch.argmax(outputs, dim=2) \n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m class_sentence \u001b[39m=\u001b[39m ner_model(sentence)\n\u001b[1;32m      2\u001b[0m class_sentence\n",
      "File \u001b[0;32m~/Desktop/KamalRaj/Assignments/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/KamalRaj/Assignments/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/KamalRaj/Assignments/.venv/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:1758\u001b[0m, in \u001b[0;36mBertForTokenClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1752\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1754\u001b[0m \u001b[39m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001b[39;00m\n\u001b[1;32m   1755\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1756\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1758\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[1;32m   1759\u001b[0m     input_ids,\n\u001b[1;32m   1760\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1761\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1762\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1763\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1764\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1765\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1766\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1767\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1768\u001b[0m )\n\u001b[1;32m   1770\u001b[0m sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1772\u001b[0m sequence_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(sequence_output)\n",
      "File \u001b[0;32m~/Desktop/KamalRaj/Assignments/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/KamalRaj/Assignments/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/KamalRaj/Assignments/.venv/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:960\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou cannot specify both input_ids and inputs_embeds at the same time\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    959\u001b[0m \u001b[39melif\u001b[39;00m input_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 960\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwarn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n\u001b[1;32m    961\u001b[0m     input_shape \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39msize()\n\u001b[1;32m    962\u001b[0m \u001b[39melif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/KamalRaj/Assignments/.venv/lib/python3.9/site-packages/transformers/modeling_utils.py:4201\u001b[0m, in \u001b[0;36mPreTrainedModel.warn_if_padding_and_no_attention_mask\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m   4198\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   4200\u001b[0m \u001b[39m# Check only the first and last input IDs to reduce overhead.\u001b[39;00m\n\u001b[0;32m-> 4201\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpad_token_id \u001b[39min\u001b[39;00m input_ids[:, [\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m0\u001b[39;49m]]:\n\u001b[1;32m   4202\u001b[0m     warn_string \u001b[39m=\u001b[39m (\n\u001b[1;32m   4203\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWe strongly recommend passing in an `attention_mask` since your input_ids may be padded. See \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4204\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhttps://huggingface.co/docs/transformers/troubleshooting\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4205\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#incorrect-output-when-padding-tokens-arent-masked.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4206\u001b[0m     )\n\u001b[1;32m   4208\u001b[0m     \u001b[39m# If the pad token is equal to either BOS, EOS, or SEP, we do not know whether the user should use an\u001b[39;00m\n\u001b[1;32m   4209\u001b[0m     \u001b[39m# attention_mask or not. In this case, we should still show a warning because this is a rare case.\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "class_sentence = ner_model(sentence)\n",
    "class_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_classifier_model = \"vblagoje/bert-english-uncased-finetuned-pos\"  # 470 MB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parts of Speech tagging is a Token classification sub-variant\n",
    "\n",
    "pos_classifier = pipeline(\"token-classification\",\n",
    "                          model=pos_classifier_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'PRON',\n",
       "  'score': 0.99954295,\n",
       "  'index': 1,\n",
       "  'word': 'i',\n",
       "  'start': 0,\n",
       "  'end': 1},\n",
       " {'entity': 'AUX',\n",
       "  'score': 0.9976078,\n",
       "  'index': 2,\n",
       "  'word': 'am',\n",
       "  'start': 2,\n",
       "  'end': 4},\n",
       " {'entity': 'ADP',\n",
       "  'score': 0.99935,\n",
       "  'index': 3,\n",
       "  'word': 'from',\n",
       "  'start': 5,\n",
       "  'end': 9},\n",
       " {'entity': 'PROPN',\n",
       "  'score': 0.99864393,\n",
       "  'index': 4,\n",
       "  'word': 'india',\n",
       "  'start': 10,\n",
       "  'end': 15},\n",
       " {'entity': 'CCONJ',\n",
       "  'score': 0.9992494,\n",
       "  'index': 5,\n",
       "  'word': 'and',\n",
       "  'start': 16,\n",
       "  'end': 19},\n",
       " {'entity': 'PRON',\n",
       "  'score': 0.99945444,\n",
       "  'index': 6,\n",
       "  'word': 'i',\n",
       "  'start': 20,\n",
       "  'end': 21},\n",
       " {'entity': 'VERB',\n",
       "  'score': 0.99256027,\n",
       "  'index': 7,\n",
       "  'word': 'like',\n",
       "  'start': 22,\n",
       "  'end': 26},\n",
       " {'entity': 'VERB',\n",
       "  'score': 0.99910283,\n",
       "  'index': 8,\n",
       "  'word': 'playing',\n",
       "  'start': 27,\n",
       "  'end': 34},\n",
       " {'entity': 'ADP',\n",
       "  'score': 0.99935657,\n",
       "  'index': 9,\n",
       "  'word': 'with',\n",
       "  'start': 35,\n",
       "  'end': 39},\n",
       " {'entity': 'NOUN',\n",
       "  'score': 0.9962528,\n",
       "  'index': 10,\n",
       "  'word': 'data',\n",
       "  'start': 40,\n",
       "  'end': 44}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_classifier(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tform",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
